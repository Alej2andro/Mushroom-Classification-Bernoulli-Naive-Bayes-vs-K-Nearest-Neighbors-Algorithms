---
title: "Proyecto üçÑ Clasificaci√≥n Supervisada de Hongos con Algoritmos Naive Bayes Bernoulli vs K-Nearest Neighbors en el Dataset Mushroom"
author: "Alejandro Figueroa Rojas"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: sandstone
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float: true
  
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
  comment = "", # elimina los '##' en la salida
  prompt = FALSE,        # ‚Üê Evita que aparezca > al inicio de l√≠neas
  results = 'hold',      # ‚Üê Opcional: agrupa todas las salidas al final
  message = FALSE, 
  warning = FALSE,fig.align = "center",cache = FALSE,fig.width = 10,fig.height = 8)
```

# Motivaci√≥n del Estudio

La clasificaci√≥n de hongos silvestres constituye un problema cr√≠tico en seguridad alimentaria y salud p√∫blica. La ingesta de especies venenosas provoca anualmente miles de intoxicaciones graves a nivel mundial, muchas de ellas fatales debido a la dificultad inherente de distinguir especies comestibles de aquellas altamente t√≥xicas bas√°ndose √∫nicamente en caracter√≠sticas morfol√≥gicas. Este proyecto aborda esta problem√°tica mediante t√©cnicas de aprendizaje supervisado, comparando dos paradigmas algor√≠tmicos fundamentalmente distintos en su aproximaci√≥n al problema de clasificaci√≥n.

El algoritmo Bernoulli Naive Bayes representa un enfoque probabil√≠stico que modela la relaci√≥n entre caracter√≠sticas y clases mediante el teorema de Bayes, asumiendo independencia condicional entre atributos. Esta simplificaci√≥n matem√°tica permite entrenamientos extremadamente r√°pidos y proporciona interpretabilidad directa sobre qu√© caracter√≠sticas discriminan mejor entre clases. Por su parte, el algoritmo K-Nearest Neighbors adopta un paradigma no param√©trico basado en similitud local, donde las predicciones emergen directamente de la estructura geom√©trica del espacio de caracter√≠sticas sin imponer supuestos distribucionales.

Utilizando el dataset Mushroom, que contiene 8,124 espec√≠menes documentados con 111 variables binarias derivadas de atributos morfol√≥gicos, ecol√≥gicos y organol√©pticos, este estudio eval√∫a sistem√°ticamente el desempe√±o de ambos modelos bajo m√∫ltiples dimensiones. El an√°lisis no se limita a comparaciones superficiales de accuracy, sino que examina rigurosamente la validez de los supuestos algor√≠tmicos subyacentes y sus consecuencias pr√°cticas en escenarios reales.

Las preguntas centrales que gu√≠an esta investigaci√≥n incluyen determinar qu√© modelo minimiza errores cr√≠ticos, espec√≠ficamente los falsos negativos que clasifican hongos venenosos como comestibles. Asimismo, se exploran los trade-offs inherentes entre interpretabilidad y precisi√≥n predictiva, as√≠ como entre velocidad computacional y requerimientos de memoria. Finalmente, se eval√∫a bajo qu√© condiciones el supuesto de independencia condicional de Naive Bayes se mantiene v√°lido versus cu√°ndo su violaci√≥n degrada significativamente el rendimiento del modelo.

El estudio integra validaci√≥n estad√≠stica formal mediante tests chi-cuadrado de asociaci√≥n, visualizaci√≥n geom√©trica multidimensional empleando t-SNE para revelar estructura de separabilidad, an√°lisis de fronteras de decisi√≥n para comprender regiones de clasificaci√≥n, y m√©tricas orientadas espec√≠ficamente al riesgo donde el recall de la clase venenosa se prioriza sobre la accuracy global. Este enfoque metodol√≥gico riguroso permite no solo identificar cu√°l algoritmo alcanza mayor precisi√≥n, sino fundamentalmente comprender por qu√© un modelo supera al otro y bajo qu√© circunstancias cada aproximaci√≥n resulta m√°s apropiada.

El objetivo final trasciende la simple comparaci√≥n de modelos. Este trabajo busca demostrar de manera rigurosa y pedag√≥gica c√≥mo los supuestos algor√≠tmicos fundamentales determinan el √©xito predictivo en problemas de clasificaci√≥n binaria con datos categ√≥ricos, proporcionando insights aplicables m√°s all√° del dominio espec√≠fico de clasificaci√≥n de hongos hacia cualquier problema donde la estructura de dependencias entre variables y el costo asim√©trico de errores sean consideraciones cr√≠ticas.


<br>

# Cargar Dataset Binario
```{r Cargar Dataset Binario}

library(caret)
library(dplyr)
library(naivebayes)
library(ggplot2)
library(e1071)
library(gridExtra)
library(knitr)

mushrooms_bin <- read.csv("data/mushrooms_bin.csv")

cat("‚úÖ Dataset binario cargado correctamente\n")
cat("Dimensiones:", dim(mushrooms_bin), "\n")

# Confirmar variable objetivo
mushrooms_bin$class <- as.factor(mushrooms_bin$class)
cat("Niveles de 'class':", levels(mushrooms_bin$class), "\n")

```
**üçÑ Definici√≥n de la Variable Objetivo (class)**

La variable objetivo en el dataset es class, la cual es binaria y define el estado de toxicidad del hongo:

- e: Comestible (edible)

- p: Venenoso (poisonous)

# Preparar datos binarios para Naive Bayes Bernoulli
```{r Preparar datos binarios para Naive Bayes Bernoulli}

# Renombramos para mantener coherencia
data_bin <- mushrooms_bin

# Aseguramos que las variables sean factores
data_binaria <- data_bin %>%
  mutate(across(where(is.character), as.factor))

cat("‚úÖ Dataset binario preparado correctamente\n")


```

## Verificaci√≥n si dataset es binario
```{r Verificaci√≥n si dataset es binario}

# Verificar valores √∫nicos en cada columna (excepto 'class')
cat("üîç Verificaci√≥n de valores binarios:\n\n")

for(col in names(data_binaria)[-which(names(data_binaria) == "class")]) {
  valores <- unique(data_binaria[[col]])
  es_binario <- all(valores %in% c(0, 1))
  
  cat(col, ": ", ifelse(es_binario, "‚úÖ BINARIO", "‚ùå NO BINARIO"), 
      " | Valores √∫nicos: ", paste(sort(valores), collapse=", "), "\n")
}

# Resumen general
todas_binarias <- all(sapply(data_binaria[, -which(names(data_binaria) == "class")], 
                              function(x) all(x %in% c(0, 1))))

cat("\nüìä RESULTADO FINAL: ", 
    ifelse(todas_binarias, "‚úÖ TODAS LAS VARIABLES SON BINARIAS {0,1}", 
           "‚ùå HAY VARIABLES NO BINARIAS"))
```
<br>

## t-SNE (t-Distributed Stochastic Neighbor Embedding)

Es una t√©cnica de reducci√≥n de dimensionalidad no lineal dise√±ada para transformar datos con muchas variables en una representaci√≥n 2D o 3D f√°cil de interpretar, sin perder la estructura esencial del conjunto original.

Su prop√≥sito principal es ***revelar patrones y grupos naturales dentro de los datos***, mostrando qu√© observaciones son similares entre s√≠ y cu√°les se diferencian de manera clara.

El algoritmo funciona identificando puntos que son ‚Äúvecinos‚Äù en el espacio original (de alta dimensi√≥n) y los ubica juntos en la proyecci√≥n final, mientras separa aquellos que son distintos. Por eso, t-SNE es especialmente efectivo para visualizar clusters y separabilidad entre clases, incluso cuando las relaciones entre variables son complejas o no lineales.

En esta visualizaci√≥n 3D, cada punto representa un hongo del dataset, y el color corresponde a su clase. Las zonas donde se forman grupos compactos indican conjuntos de observaciones con patrones de atributos muy similares, mientras que las separaciones marcadas reflejan diferencias fuertes entre clases. Las √°reas de transici√≥n corresponden a ejemplares con caracter√≠sticas intermedias, m√°s dif√≠ciles de clasificar.

En conjunto, t-SNE te permite ver la estructura interna del dataset ‚Äúdesde arriba‚Äù: c√≥mo se organizan los datos, qu√© tan separables son las clases y d√≥nde se ubican los casos l√≠mite que podr√≠an generar confusi√≥n en un modelo predictivo.

### Reducci√≥n de dimensionalidad y visualizaci√≥n 3D con t-SNE
```{r separabilidad clases(t-sne),fig.width=14, fig.height=9, out.width="100%", out.height="800px"}

library(Rtsne)
library(plotly)

set.seed(123)
tsne <- Rtsne(mushrooms_bin[, -ncol(mushrooms_bin)], 
              dims = 3, perplexity = 30,
              check_duplicates = FALSE)

plot_ly(x = tsne$Y[,1], y = tsne$Y[,2], z = tsne$Y[,3],
        color = mushrooms_bin$class,
        colors = c("e" = "#8E44AD", "p" = "#F57C00"),
        type = 'scatter3d', mode = 'markers',
        marker = list(size = 2, opacity = 0.6)) %>%
  layout(title = "Separabilidad con t-SNE 3D",
         scene = list(xaxis = list(title = 'Dim1'),
                      yaxis = list(title = 'Dim2'),
                      zaxis = list(title = 'Dim3')))

cat(
  "\nüí° Las m√∫ltiples nubes moradas reflejan heterogeneidad:\n",
  "   Hongos comestibles = Muchas combinaciones v√°lidas.\n",
  "   Hongos venenosos = M√°s homog√©neos (cluster naranjas central).\n",
  sep = ""
)
```

**Interpretaci√≥n del gr√°fico t-SNE 3D**

Estructura observada:

La visualizaci√≥n revela 5-6 clusters morados (comestibles) dispersos vs 1 cluster naranjas grande (venenosos) en el centro, con algunos grupos rojos menores aislados.

Significado de m√∫ltiples nubes moradas:

Los hongos comestibles presentan mayor heterogeneidad fenot√≠pica ‚Äî existen m√∫ltiples combinaciones de caracter√≠sticas (olor, color, forma) que resultan en comestibilidad. Cada nube morada representa un "arquetipo" diferente de hongo comestible:

- Cluster morado superior: posiblemente hongos con olor almendrado + sombrero convexo
- Cluster morado inferior izquierdo: quiz√°s sin olor + l√°minas libres
- Clusters morados laterales: otras combinaciones distintas de atributos

En contraste, los hongos venenosos est√°n m√°s concentrados porque comparten patrones t√≥xicos comunes (ej: olor f√©tido + color espec√≠fico + h√°bitat).

Implicaci√≥n biol√≥gica:

La naturaleza es "conservadora" con toxicidad (pocos patrones venenosos efectivos) pero "diversa" en comestibilidad (muchas estrategias evolutivas viables). t-SNE captura esta asimetr√≠a estructural que las 111 variables binarias 

Regiones de transici√≥n: Las zonas donde el morado y el rojo se acercan corresponden a hongos con caracter√≠sticas intermedias, es decir, casos cuyos atributos se sit√∫an cerca del ‚Äúumbral de decisi√≥n‚Äù entre ambas clases. Son los ejemplares m√°s dif√≠ciles de clasificar, porque sus vectores de caracter√≠sticas presentan similitudes tanto con los arquetipos de hongos comestibles como con los venenosos.

<br>

# Prueba de Asociaci√≥n œá¬≤ para Variables Predictoras

Antes de entrenar cualquier modelo de clasificaci√≥n, es fundamental verificar si existe una asociaci√≥n estad√≠sticamente significativa entre cada variable predictora y la clase objetivo (comestible/venenoso). Esta validaci√≥n previa nos permite identificar qu√© caracter√≠sticas del hongo contienen informaci√≥n discriminante real y cu√°les podr√≠an ser ruido aleatorio.

Test œá¬≤ de Pearson de IndependenciaEl test œá¬≤ de Pearson 

eval√∫a la independencia entre dos variables categ√≥ricas mediante la comparaci√≥n de las frecuencias observadas en los datos frente a las frecuencias que esperar√≠amos ver si ambas variables fueran completamente independientes. Un p-valor < 0.05 nos permite rechazar la hip√≥tesis nula y concluir que la variable contiene informaci√≥n √∫til para discriminar entre hongos comestibles y venenosos.

En t√©rminos simples: el test œá¬≤ compara lo que "deber√≠a pasar" si la variable y la clase fueran independientes (es decir, si no tuvieran relaci√≥n alguna) con lo que realmente observamos en nuestros datos. Cuanto mayor sea la discrepancia entre lo esperado y lo observado, m√°s poder predictivo tiene esa variable.

Criterio de decisi√≥n:

Si œá¬≤calculado > œá¬≤cr√≠tico ‚Üí se rechaza H‚ÇÄ (la variable S√ç discrimina entre clases)

Formalmente, el test contrasta la hip√≥tesis nula mediante el estad√≠stico:

$$
\chi^2 = \sum \frac{(O_{ij} - E_{ij})^2}{E_{ij}}
$$

donde: \(O_{ij}\) son las frecuencias observadas en cada celda y \(E_{ij}\) las frecuencias esperadas bajo el supuesto de independencia entre las variables.


Nota metodol√≥gica: Los supuestos del test (frecuencias esperadas ‚â• 5 en ‚â• 80% de celdas) se cumplen holgadamente en este dataset debido a que todas las variables son binarias {0,1} con suficientes observaciones en cada combinaci√≥n. La ausencia de warnings en R confirma que las condiciones de validez se satisfacen.

## Definici√≥n del Marco de Hip√≥tesis para test œá¬≤
```{r Definici√≥n del Marco de Hip√≥tesis para test œá¬≤}

alpha <- 0.05

cat(
  "\n=== Marco de H√≠potesis para el test œá¬≤ ===\n\n",
  
  "Hip√≥tesis:\n",
  "  H‚ÇÄ: La variable es independiente de la clase (NO discrimina)\n",
  "  H\u2090: La variable est√° asociada con la clase (S√ç discrimina)\n\n",
  
  sprintf("Criterio de decisi√≥n:\n  Si œá¬≤calc > œá¬≤crit(Œ±=%.2f) ‚Üí Rechazar H‚ÇÄ\n\n", alpha),
  
  "Interpretaci√≥n:\n",
  "  ‚Ä¢ Rechazar H‚ÇÄ = la variable ayuda a predecir toxicidad\n",
  "  ‚Ä¢ No rechazar H‚ÇÄ = la variable no contiene informaci√≥n √∫til\n",
  sep = ""
)

```

## C√°lculo del Test œá¬≤ para Todas las Variables
```{r ,C√°lculo del Test œá¬≤ para Todas las Variables}

cat("Test œá¬≤ de independencia: asociaci√≥n con la clase (comestible/venenoso)\n\n")

chi_results <- lapply(names(mushrooms_bin)[names(mushrooms_bin) != "class"], function(var) {
  tabla <- table(mushrooms_bin[[var]], mushrooms_bin$class)
  test <- chisq.test(tabla, correct = FALSE)
  
  gl <- test$parameter
  chi2_calc <- test$statistic
  chi2_crit <- qchisq(1 - alpha, gl)
  p_val <- test$p.value
  
  # Decisi√≥n estad√≠stica
  if(chi2_calc > chi2_crit) {
    decision <- "Rechaza H0"
    significancia <- "Variable SIGNIFICATIVA"
  } else {
    decision <- "No rechaza H0"
    significancia <- "Variable NO significativa"
  }
  
  data.frame(
    Variable = var,
    Chi2_Calculado = round(chi2_calc, 2),
    Chi2_Critico = round(chi2_crit, 2),
    gl = gl,
    p_valor = ifelse(p_val < 2.2e-16, "< 2.2e-16", 
                     format(p_val, scientific = TRUE, digits = 3)),
    Decision = decision,
    Interpretacion = significancia,
    stringsAsFactors = FALSE
  )
})

chi_df <- do.call(rbind, chi_results)
chi_df <- chi_df[order(chi_df$Chi2_Calculado, decreasing = TRUE), ]
row.names(chi_df) <- NULL

# Mostrar top 15 con nombres de columnas seguros
kable(head(chi_df, 15),
      col.names = c("Variable", "Chi2 Calculado", "Chi2 Critico", 
                    "g.l.", "p-valor", "Decision", "Interpretacion"),
      caption = "Top 15 variables con mayor asociacion estadistica",
      align = "lcccclc")



```

## Interpretaci√≥n de los Resultados del Test œá¬≤
```{r Interpretaci√≥n de los Resultados del Test œá¬≤}

n_significativas <- sum(chi_df$Decision == "Rechaza H‚ÇÄ")
n_total <- nrow(chi_df)

cat(
  "\n=== INTERPRETACI√ìN GLOBAL ===\n\n",
  
  sprintf("RESULTADOS SOBRE LAS %d VARIABLES:\n", n_total),
  sprintf("  ‚Ä¢ Variables significativas: %d (%.1f%%)\n", 
          n_significativas, (n_significativas/n_total)*100),
  sprintf("  ‚Ä¢ Todas con p-valor < 2.2e-16 (evidencia extrema)\n\n"),
  
  "HALLAZGOS CLAVE:\n",
  sprintf("  ‚Ä¢ Variable m√°s discriminante: %s (œá¬≤=%.2f)\n", 
          chi_df$Variable[1], chi_df$Chi2_Calculado[1]),
  sprintf("  ‚Ä¢ Valor cr√≠tico t√≠pico: ~%.2f (gl=%d)\n", 
          chi_df$Chi2_Critico[1], chi_df$gl[1]),
  sprintf("  ‚Ä¢ Ratio œá¬≤calc/œá¬≤crit: ~%.0f√ó en la variable top\n\n",
          chi_df$Chi2_Calculado[1]/chi_df$Chi2_Critico[1]),
  
  "CONCLUSI√ìN:\n",
  "  Todas las variables one-hot encoded contienen informaci√≥n\n",
  "  estad√≠sticamente significativa para predecir toxicidad.\n",
  "  Ninguna puede considerarse ruido aleatorio.\n",
  sep = ""
)
```


## Divisi√≥n en conjuntos de entrenamiento y prueba
```{r split in train and test}

set.seed(123)
train_index <- createDataPartition(mushrooms_bin$class, p = 0.8, list = FALSE)

train_data <- mushrooms_bin[train_index, ]
test_data  <- mushrooms_bin[-train_index, ]

cat("Conjunto de entrenamiento:", nrow(train_data), "observaciones\n")
cat("Conjunto de prueba:", nrow(test_data), "observaciones\n")

```
<br>

# Modelamiento: Naive Bayes Bernoulli

## Fundamentos Te√≥ricos

### 1. Definici√≥n del Algoritmo

El **Naive Bayes Bernoulli** es un clasificador probabil√≠stico especializado para datos con **caracter√≠sticas binarias** $X_k \in \{0,1\}$, fundamentado en el teorema de Bayes y el supuesto de independencia condicional entre atributos.

### 2. Teorema de Bayes Aplicado a Clasificaci√≥n

Para una instancia con vector de caracter√≠sticas $\mathbf{X} = (X_1, X_2, \dots, X_p)$ y clases $G \in \{1, 2, \dots, K\}$, el clasificador asigna la clase con mayor probabilidad posterior:

$$
\hat{G}(\mathbf{X}) = \arg\max_{j \in \{1,\dots,K\}} P(G=j|\mathbf{X})
$$

Aplicando el teorema de Bayes:

$$
P(G=j|\mathbf{X}) = \frac{P(\mathbf{X}|G=j) \cdot P(G=j)}{P(\mathbf{X})} \propto P(\mathbf{X}|G=j) \cdot P(G=j)
$$

donde $P(G=j)$ es la **probabilidad a priori** de la clase $j$.

### 3. Supuesto de Independencia Condicional ("Naive")

El modelo asume que, dado $G=j$, las caracter√≠sticas son **condicionalmente independientes**:

$$
P(\mathbf{X}|G=j) = P(X_1, X_2, \dots, X_p|G=j) = \prod_{k=1}^{p} P(X_k|G=j)
$$

**Implicaci√≥n clave:** Este supuesto reduce la estimaci√≥n de $P(\mathbf{X}|G=j)$ de $O(2^p)$ par√°metros a $O(p)$, haciendo el modelo computacionalmente eficiente.

**Aclaraci√≥n importante:** La independencia es **condicional** dada la clase, no incondicional. Las caracter√≠sticas pueden estar correlacionadas en la poblaci√≥n general, pero el modelo asume que dentro de cada clase espec√≠fica, conocer el valor de una caracter√≠stica no proporciona informaci√≥n adicional sobre otras. Esta distinci√≥n es fundamental para comprender las limitaciones del modelo.

### 4. Modelado con Distribuci√≥n de Bernoulli

Cada caracter√≠stica binaria $X_k$ se modela mediante una **distribuci√≥n de Bernoulli**:

$$
P(X_k = x_k | G=j) = \mu_{jk}^{x_k} (1 - \mu_{jk})^{1-x_k}, \quad x_k \in \{0,1\}
$$

donde $\mu_{jk} = P(X_k=1|G=j)$ representa la probabilidad de que la caracter√≠stica $k$ est√© "activa" (valor 1) en la clase $j$.

**Propiedades estad√≠sticas de Bernoulli($\mu$):**

- Media: $\mathbb{E}[X_k] = \mu_{jk}$
- Varianza: $\text{Var}[X_k] = \mu_{jk}(1-\mu_{jk})$ (heterocedasticidad inherente)

### 5. Regla de Clasificaci√≥n Final

Sustituyendo en Bayes y aplicando logaritmo natural para estabilidad num√©rica:

$$
\hat{G}(\mathbf{X}) = \arg\max_{j} \left[ \log P(G=j) + \sum_{k=1}^{p} \left( x_k \log \mu_{jk} + (1-x_k) \log(1-\mu_{jk}) \right) \right]
$$

El logaritmo evita underflow num√©rico al multiplicar muchas probabilidades peque√±as.

### 6. Estimaci√≥n de Par√°metros

Dado un conjunto de entrenamiento $\{(\mathbf{x}_i, g_i)\}_{i=1}^{N}$, los par√°metros se estiman mediante **m√°xima verosimilitud (MLE)**:

**Probabilidades a priori:**

$$
\hat{P}(G=j) = \frac{N_j}{N}, \quad N_j = \sum_{i=1}^{N} \mathbb{1}(g_i = j)
$$

**Par√°metros de Bernoulli:**

$$
\hat{\mu}_{jk} = \frac{\sum_{i: g_i=j} x_{ik}}{N_j}
$$

**Suavizado de Laplace** (para evitar $\mu_{jk}=0$ o $\mu_{jk}=1$):

$$
\hat{\mu}_{jk}^{\text{smooth}} = \frac{\sum_{i: g_i=j} x_{ik} + \alpha}{N_j + 2\alpha}, \quad \alpha \geq 0
$$

donde $\alpha=1$ es el valor est√°ndar (suavizado de Laplace), y $\alpha=0$ corresponde a estimaci√≥n por m√°xima verosimilitud pura sin regularizaci√≥n.

### 7. Interpretaci√≥n Geom√©trica

En el espacio $\mathbb{R}^p$, Bernoulli Naive Bayes define **fronteras de decisi√≥n lineales** (hiperplanos) en el espacio log-odds. Para clasificaci√≥n binaria ($K=2$):

$$
\log \frac{P(G=1|\mathbf{X})}{P(G=2|\mathbf{X})} = \beta_0 + \sum_{k=1}^{p} \beta_k x_k
$$

con coeficientes:

$$
\beta_k = \log \frac{\mu_{1k}(1-\mu_{2k})}{\mu_{2k}(1-\mu_{1k})}
$$

Esto implica que el modelo separa las clases mediante combinaciones lineales de las caracter√≠sticas binarias.

### 8. Ventajas y Limitaciones

**Fortalezas:**

- **Eficiencia computacional:** Entrenamiento en $O(Np)$ - extremadamente r√°pido
- **Robustez dimensional:** Funciona bien con alta dimensionalidad ($p \gg N$)
- **Interpretabilidad:** $\mu_{jk}$ cuantifica directamente la relevancia de cada caracter√≠stica
- **Tolerancia al ruido:** Reducci√≥n de varianza compensa parcialmente el sesgo introducido

**Debilidades:**

- **Sesgo por independencia violada:** No captura interacciones entre variables
- **Requisito de binaridad:** Asume variables genuinamente binarias
- **Calibraci√≥n sub√≥ptima:** Las probabilidades no est√°n bien calibradas (√∫til para ranking, no probabilidades absolutas)

### 9. Conexi√≥n con el Dataset Mushroom

En el problema de clasificaci√≥n de hongos:

- $p=111$ variables one-hot encoded (olor, color, h√°bitat, textura, etc.)
- $K=2$ clases (comestible/venenoso)
- $N=6{,}500$ observaciones de entrenamiento

El modelo estima $111 \times 2 = 222$ par√°metros $\mu_{jk}$, capturando patrones discriminantes como:

$$
\mu_{\text{venenoso, odor\_foul}} \approx 0.85 \quad \text{vs.} \quad \mu_{\text{comestible, odor\_foul}} \approx 0.05
$$

revelando que el olor f√©tido es un fuerte indicador de toxicidad.

---

**Nota sobre el bias-variance tradeoff:** La independencia condicional es una **simplificaci√≥n dr√°stica** de la realidad biol√≥gica (caracter√≠sticas como color y textura frecuentemente correlacionan). Sin embargo, el sesgo introducido por este supuesto es compensado por la reducci√≥n de varianza en datasets peque√±os a medianos. Este fen√≥meno, conocido como **bias-variance tradeoff** favorable para Naive Bayes, explica por qu√© el modelo puede alcanzar buen desempe√±o incluso cuando sus supuestos son violados.

<br>

## Entrenamiento del Modelo NB Bernoulli
```{r Entrenamiento del Modelo Bernoulli NB}

set.seed(123)

# Modelo simple sin CV para visualizaci√≥n
modelo_base <- naive_bayes(class ~ ., data = train_data, laplace = 0)

cat("‚úÖ Modelo base entrenado\n")
cat("Tipo:", ifelse(all(sapply(train_data[,-ncol(train_data)], 
    function(x) all(x %in% c(0,1)))), "Bernoulli", "Otro"), "\n")

```
## Entrenamiento con validaci√≥n cruzada
```{r Entrenamiento con validaci√≥n cruzada}

set.seed(123)
ctrl <- trainControl(method="cv", number=10)

modelo_cv <- train(
  class ~ .,data = train_data,method = "naive_bayes",trControl = ctrl,
  tuneGrid = expand.grid( usekernel = c(FALSE, TRUE),laplace = 0,
    adjust = 1))

cat("‚úÖ Modelo CV entrenado\n")
print(modelo_cv)
```
**Interpretaci√≥n Validaci√≥n Cruzada 10-fold y Selecci√≥n del Modelo Final**

El proceso de entrenamiento se realiz√≥ sobre las **6.500 observaciones** del conjunto de entrenamiento, utilizando **111 variables predictoras binarias** (0/1) derivadas del one-hot encoding de los atributos originales del dataset Mushroom.

La variable objetivo presenta dos clases:  

- `e` ‚Üí comestible (*edible*)  
- `p` ‚Üí venenoso (*poisonous*)


**No se aplic√≥ ning√∫n preprocesamiento** (escalado, centrado, etc.), lo cual es correcto y deseable: el modelo Bernoulli Naive Bayes requiere exclusivamente variables binarias y nuestro dataset ya cumple esta condici√≥n.

Se emple√≥ **validaci√≥n cruzada estratificada de 10 folds**, m√©todo est√°ndar para obtener una estimaci√≥n robusta y sin sesgo del rendimiento real del modelo. En cada iteraci√≥n, aproximadamente el 80% de los datos se us√≥ para entrenamiento y el 20% restante para validaci√≥n.

Evaluaci√≥n de hiperpar√°metros:


| usekernel | Modelo                               | Accuracy (CV) | Kappa (CV) |
|-----------|---------------------------------------|---------------|------------|
| FALSE     | **Bernoulli Naive Bayes cl√°sico**     | **0.9397**    | **0.8791** |
| TRUE      | Naive Bayes con estimaci√≥n kernel     | 0.9342        | 0.8678     |


Hiperpar√°metros mantenidos constantes: 

- `laplace = 0` ‚Üí sin suavizado (apropiado: no existen ceros estructurales cr√≠ticos tras el one-hot encoding)  
- `adjust = 1` ‚Üí valor por defecto del ajuste de bandwidth (solo afecta al caso kernel)

Modelo seleccionado autom√°ticamente

**Bernoulli Naive Bayes cl√°sico** 

Configuraci√≥n final: `usekernel = FALSE`, `laplace = 0`, `adjust = 1`

**M√©tricas promedio en validaci√≥n cruzada**  

- **Accuracy ‚âà 93.97 %**  
- **Kappa ‚âà 0.879** ‚Üí acuerdo casi perfecto seg√∫n la escala de Landis y Koch

**Conclusi√≥n**

La validaci√≥n cruzada confirm√≥ de forma contundente que, para un conjunto de datos completamente binarizado como el presente, la versi√≥n **cl√°sica de Bernoulli Naive Bayes (sin kernel)** supera claramente a la variante basada en estimaci√≥n de densidad kernel.

El modelo resultante es:  

- Extremadamente simple y r√°pido  
- Altamente interpretable  
- Robusto y con excelente capacidad discriminante (~94% de precisi√≥n)  
- √ìptimo para el problema planteado

Por ello, se adopta como **modelo definitivo** para la clasificaci√≥n de hongos comestibles y venenosos en este estudio.

**La validaci√≥n cruzada 10-fold determin√≥ que el Bernoulli Naive Bayes cl√°sico (sin kernel ni suavizado Laplace) es el modelo √≥ptimo y estable para este dataset binario, alcanzando un rendimiento promedio de 93.97 % de accuracy y un Kappa de 0.879, lo que representa una capacidad discriminante excelente y robusta entre hongos comestibles y venenosos.**

<br>

## An√°lisis de Separabilidad con Top 6 Variables M√°s Discriminantes (ggpairs)
```{r ggpairs-top6, fig.width=16,fig.height=8}

library(GGally)

# Obtener top 6 variables
importancia <- varImp(modelo_cv)
top6_vars <- rownames(head(
  importancia$importance[order(-importancia$importance[,1]), , drop=FALSE], 
  6
))

# Preparar datos para ggpairs
datos_ggpairs <- train_data[, c(top6_vars, "class")] %>%
  mutate(across(all_of(top6_vars), as.numeric)) %>%
  mutate(class = factor(class, labels = c("Comestible", "Venenoso")))

# Crear nombres de columnas m√°s legibles y compactos
nombres_legibles <- c("Olor\nAusente", "Olor\nF√©tido", 
  "Tallo\nSup.\nAnillo","Tipo\nAnillo",
  "Tallo\nInf.\nAnillo","Magull.","Clase")

# Crear ggpairs con configuraci√≥n optimizada para legibilidad
ggpairs(
  datos_ggpairs,
  aes(color = class, alpha = 0.6),
  
  # Tri√°ngulo superior: correlaciones
  upper = list(
    continuous = wrap("cor", size = 4.5, stars = FALSE)
  ),
  
  # Tri√°ngulo inferior: dispersi√≥n
  lower = list(
    continuous = wrap(
      "points", 
      alpha = 0.4, 
      size = 1.2,
      position = position_jitter(width = 0.1, height = 0.1)
    )
  ),
  
  # Diagonal: densidades
  diag = list(
    continuous = wrap(
      "densityDiag", 
      alpha = 0.7,
      bw = "SJ"
    )
  ),
  
  # Etiquetas personalizadas m√°s compactas
  columnLabels = nombres_legibles,
  title = "Matriz de Separabilidad: Top 6 Variables M√°s Discriminantes"
) +
  scale_fill_manual(values = c("Comestible" = "#8E44AD", "Venenoso" = "#F57C00")) +
  scale_color_manual(values = c("Comestible" = "#8E44AD", "Venenoso" = "#F57C00")) +
  theme_minimal(base_size = 13) +
  theme(
    # T√≠tulo principal
    plot.title = element_text(
      hjust = 0.5, 
      face = "bold", 
      size = 16,
      margin = margin(b = 10)
    ),
    
    # CR√çTICO: Etiquetas de las variables en los bordes (strip)
    strip.text.x = element_text(
      size = 11,           # Tama√±o ajustado para que quepa todo
      face = "bold",
      angle = 0,           # Horizontal
      lineheight = 0.9,    # Espaciado entre l√≠neas del texto
      margin = margin(t = 2, b = 2)
    ),
    strip.text.y = element_text(
      size = 11,
      face = "bold",
      angle = 0,           # Vertical pero legible
      lineheight = 0.9,
      margin = margin(l = 2, r = 2)
    ),
    
    # N√∫meros en los ejes (0.00, 0.25, 0.50, etc.)
    axis.text.x = element_text(
      size = 10,
      angle = 45,          # √Ångulo para evitar solapamiento
      hjust = 1,
      vjust = 1
    ),
    axis.text.y = element_text(
      size = 10
    ),
    
    # T√≠tulos de los ejes (si se muestran)
    axis.title = element_text(
      size = 11, 
      face = "bold"
    ),
    
    # Leyenda
    legend.position = "bottom",
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 12, face = "bold"),
    legend.box.spacing = unit(0.3, "cm"),
    
    # Espaciado entre paneles
    panel.spacing = unit(0.3, "lines"),
    
    # M√°rgenes generales
    plot.margin = margin(t = 10, r = 10, b = 10, l = 10)
  )
```
<br>

**Interpretaci√≥n de la Matriz de Separabilidad**

***nota sobre diagonal***

Las variables son binarias discretas {0, 1}, no continuas. Los gr√°ficos de densidad en la diagonal intentan suavizar esta distribuci√≥n discreta, pero cuando una clase tiene varianza cero (todos los valores son id√©nticos), no hay "densidad" que graficar para esa clase espec√≠fica.

La matriz ggpairs eval√∫a las seis variables m√°s discriminantes revelando tanto su poder predictivo individual como las violaciones del supuesto de independencia condicional requerido por Bernoulli Naive Bayes.

**Diagonal: Poder discriminante individual**

Los gr√°ficos de densidad muestran separaci√≥n bimodal en variables como `Olor Ausente` y `Olor F√©tido`: picos naranjas y morados en valores distintos indican alto poder predictivo. Los espacios vac√≠os en algunas densidades son correctos y esperables: ocurren cuando una clase tiene varianza cercana a cero (ej: si todos los hongos venenosos carecen de "olor ausente", no hay densidad que graficar para esa clase).

Trat√°ndose de variables binarias {0,1}, esta "separaci√≥n" representa diferencias en proporciones por clase, no distribuciones continuas desplazadas.

**Tri√°ngulo inferior: Estructura discreta**

Los diagramas de dispersi√≥n con jitter revelan que las observaciones reales ocupan solo cuatro posiciones: (0,0), (0,1), (1,0), (1,1). El jitter es artefacto visual para evitar solapamiento. Los "cl√∫steres de color" indican frecuencias relativas, no reglas determin√≠sticas: color naranja predominante en cierta coordenada significa que en esa combinaci√≥n la mayor√≠a son hongos venenosos, pero no necesariamente el 100%.

**Tri√°ngulo superior: Violaci√≥n cr√≠tica del supuesto de independencia**

Cada celda muestra tres correlaciones: global (Corr), condicional en comestibles, y condicional en venenosos. El supuesto de Naive Bayes requiere correlaciones **condicionales dentro de cada clase** cercanas a cero. Los datos refutan este supuesto:

- **Violaci√≥n moderada**: `Olor Ausente` vs `Olor F√©tido` en venenosos: -0.203 (los tipos de olor no son independientes)
- **Violaci√≥n severa**: `Tipo Anillo` vs `Tallo Inf. Anillo` en venenosos: 0.529 (tipo de anillo y textura de tallo est√°n fuertemente correlacionados)
- **Violaci√≥n cr√≠tica**: `Magull.` vs `Tallo Inf. Anillo`: 0.591 en comestibles y 0.848 en venenosos (magulladuras y textura capturan aspectos morfol√≥gicos relacionados)

**Implicaci√≥n directa**: Estas correlaciones altas explican los **51 falsos negativos** del modelo. Combinaciones espec√≠ficas de caracter√≠sticas que conjuntamente indican toxicidad no pueden ser capturadas por un modelo que eval√∫a cada variable aisladamente bajo el supuesto de independencia.

**Conclusi√≥n**: El modelo alcanza 94.09% accuracy **a pesar de** violar severamente el supuesto de independencia, no porque lo cumpla. Las variables individuales son suficientemente discriminantes para compensar parcialmente esta violaci√≥n, pero los errores cr√≠ticos ocurren precisamente donde las interacciones entre variables son determinantes para la clasificaci√≥n correcta.

> **Nota t√©cnica**: La matriz documenta emp√≠ricamente por qu√© Bernoulli NB es sub√≥ptimo para este problema. El contraste con KNN (0 errores) confirma que la estructura de dependencias en el espacio de 111 variables contiene informaci√≥n cr√≠tica que Naive Bayes no puede aprovechar bajo su marco simplificado de independencia condicional.

<br>

## Frontera de Decisi√≥n de Naive Bayes Bernoulli
```{r linea-decision-bernoulli, fig.width=11, fig.height=9}

# Obtener top 2 variables del modelo CV
importancia <- varImp(modelo_cv)
top2 <- rownames(head(importancia$importance[
  order(-importancia$importance[,1]), , drop=FALSE], 2))

# Preparar datos con jitter
data_viz <- train_data[, c(top2, "class")]
colnames(data_viz)[1:2] <- c("X1", "X2")
data_viz$X1_jitter <- jitter(data_viz$X1, factor=2)
data_viz$X2_jitter <- jitter(data_viz$X2, factor=2)

# Grid de predicci√≥n
grid <- expand.grid(
  X1 = seq(-0.3, 1.3, length.out=200),
  X2 = seq(-0.3, 1.3, length.out=200)
)

# Crear datos para predicci√≥n (columnas con nombres originales)
grid_pred_data <- as.data.frame(matrix(0, nrow=nrow(grid), ncol=ncol(train_data)-1))
colnames(grid_pred_data) <- setdiff(names(train_data), "class")
grid_pred_data[, top2[1]] <- round(pmax(0, pmin(1, grid$X1)))
grid_pred_data[, top2[2]] <- round(pmax(0, pmin(1, grid$X2)))

# Predicci√≥n
grid$pred <- predict(modelo_cv, newdata=grid_pred_data)

# Gr√°fico
ggplot() +
  geom_tile(data=grid, aes(X1, X2, fill=pred), alpha=0.3) +
  geom_point(data=data_viz, aes(X1_jitter, X2_jitter, color=class), 
             size=1.5, alpha=0.7) +
  scale_fill_manual(values=c("e"="#A569BD", "p"="#e74c3c"),
                    name="Regi√≥n predicha") +
  scale_color_manual(values=c("e"="#8E44AD", "p"="#F57C00"),
                     name="Clase real") +
  labs(title="Frontera de Decisi√≥n - Naive Bayes Bernoulli",
       subtitle=paste(top2[1], "vs", top2[2]),
       x=top2[1], y=top2[2]) +
  theme_minimal(base_size=12) +
  theme(
    plot.title = element_text(hjust=0.5, face="bold"),
    plot.subtitle = element_text(hjust=0.5),
    legend.position = "right",
    legend.title = element_text(size=14, face="bold"),
    legend.text = element_text(size=12),
    legend.key.size = unit(1.5, "lines")
  )
```
<br>

**Interpretaci√≥n de la Frontera de Decisi√≥n (Naive Bayes Bernoulli)**

La gr√°fica muestra la frontera de decisi√≥n generada por el modelo Bernoulli Naive Bayes, utilizando las dos variables m√°s influyentes seg√∫n la importancia obtenida en validaci√≥n cruzada.

El fondo coloreado representa la regi√≥n de predicci√≥n del modelo:

- Morado: zona donde el modelo predice clase comestible (e).

- Naranja: zona donde el modelo predice clase venenosa (p), si corresponde.

Dado que estas variables son binarias (0/1), la frontera de decisi√≥n adopta bloques rectangulares en lugar de l√≠neas curvas. Esto es totalmente coherente con la estructura de un modelo Bernoulli, donde el espacio se divide en combinaciones discretas de valores.

Sobre estas regiones se superponen los puntos reales del conjunto de entrenamiento (con jitter a√±adido para evitar solapamientos), donde:

- Los puntos morados representan casos reales de clase e.

- Los puntos naranja representan casos reales de clase p.

¬øPor qu√© algunos puntos parecen sobresalir del bloque verde?

Esto ocurre por dos razones complementarias:

- Efecto del jitter (visualizaci√≥n):

Aunque los valores reales son exactamente 0 o 1, el jitter desplaza ligeramente los puntos para que no queden todos superpuestos.
Este desplazamiento hace que muchos puntos parezcan ‚Äúsalir‚Äù visualmente del cuadrado, pero no representan un error del modelo, sino una mejora en la legibilidad.

- Limitaciones naturales del modelo:

El Bernoulli Naive Bayes asume independencia entre variables y trabaja con categor√≠as estrictas.
En zonas donde ambas clases comparten combinaciones similares de 0/1, algunos puntos pueden quedar en la regi√≥n predicha incorrecta, revelando √°reas donde el solapamiento entre clases dificulta la separaci√≥n perfecta.

Esta combinaci√≥n permite visualizar simult√°neamente:

- C√≥mo el modelo divide el espacio de caracter√≠sticas.

- La distribuci√≥n real de las observaciones.

- Las zonas donde existe mayor o menor solapamiento entre ambas clases.

- Las √°reas en las cuales el modelo puede cometer errores o mostrar menor confianza.

**Conclusi√≥n**

El gr√°fico ofrece una representaci√≥n clara de c√≥mo el modelo Bernoulli Naive Bayes asigna categor√≠as usando pares de variables binarias. La forma cuadrada de la frontera y la dispersi√≥n visual ampliada por el jitter permiten comprender, de manera intuitiva, la relaci√≥n entre las predicciones del modelo y las observaciones reales, destacando tanto las zonas de acierto como los sectores de mayor ambig√ºedad entre clases.

<br>

## Predicciones en test set 
```{r Predicciones en test set}

pred_clasificacion <- predict(modelo_cv, newdata = test_data)

tabla <- table(pred_clasificacion)
texto_tabla <- paste(names(tabla), tabla, sep=": ", collapse="\n  ")

cat(paste0(
  "\n‚úÖ Predicciones generadas correctamente\n",
  "  Total de predicciones: ", length(pred_clasificacion), "\n",
  "  Distribuci√≥n de clases predichas:\n  ",
  texto_tabla, "\n"
))
```

Recordar :

- e = edible (comestible)
- p = poisonous (venenoso)

<br>

## Evaluaci√≥n del Modelo en Test Set
```{r Evaluaci√≥n del Modelo en Test Set}

# Usar las predicciones ya generadas (pred_todo)
conf_matrix <- confusionMatrix(pred_clasificacion, test_data$class, positive = "p")

cat("\nüìä MATRIZ DE CONFUSI√ìN (Test Set):\n")
print(conf_matrix$table)

# M√©tricas cr√≠ticas
recall_venenoso <- conf_matrix$byClass['Sensitivity']
fn_criticos <- conf_matrix$table[1, 2]  # Falsos negativos

cat("\nüö® M√âTRICA CR√çTICA - Recall (venenoso):", round(recall_venenoso, 4), "\n")
cat("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n")
cat("  ‚Üí Detecta correctamente", round(recall_venenoso*100, 1), "% de hongos venenosos\n")
cat("  ‚Üí Falsos negativos (CR√çTICOS):", fn_criticos, 
    "hongos venenosos clasificados como comestibles ‚ö†Ô∏è\n")

cat("\nüìà M√©tricas generales:\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
cat("  Accuracy:", round(conf_matrix$overall['Accuracy'], 4), "\n")
cat("  Kappa:", round(conf_matrix$overall['Kappa'], 4), "\n")
cat("  Sensitivity (Recall):", round(conf_matrix$byClass['Sensitivity'], 4), "\n")
cat("  Specificity:", round(conf_matrix$byClass['Specificity'], 4), "\n")
cat("  Precision:", round(conf_matrix$byClass['Pos Pred Value'], 4), "\n")
cat("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n")

```

<br>

**Interpretaci√≥n**

Recordar: 

- e = comestible
- p = venenoso

La matriz de confusi√≥n muestra un desempe√±o s√≥lido del modelo Bernoulli Naive Bayes en la clasificaci√≥n de hongos, con m√©tricas globales altas pero un error cr√≠tico a considerar.
M√©tricas por clase:

- Sensitivity (Recall para venenosos) = 0.9349: El modelo detecta correctamente el 93.5% de los hongos venenosos. Sin embargo, 51 hongos venenosos fueron clasificados como comestibles (falsos negativos), lo que representa un riesgo cr√≠tico inaceptable en aplicaciones reales donde un error de este tipo podr√≠a causar intoxicaciones graves.

- Specificity = 0.9465: El modelo identifica correctamente el 94.65% de los hongos comestibles, evitando clasificarlos err√≥neamente como venenosos. Solo 45 comestibles fueron marcados como peligrosos (falsos positivos), lo que representa un error conservador y seguro.

- Precision = 0.9421: De todos los hongos que el modelo predice como venenosos, el 94.21% efectivamente lo son. Esto indica alta confiabilidad en las alertas de peligro.

Desempe√±o global:

- Accuracy = 0.9409: El modelo acierta en el 94.09% de las predicciones totales.
- Kappa = 0.8816: Acuerdo casi perfecto, muy superior al azar.

**Conclusi√≥n**

El modelo es consistente y preciso, pero los 51 falsos negativos representan una limitaci√≥n seria para su uso directo en clasificaci√≥n de hongos sin supervisi√≥n experta.

<br>

## C√°lculo del AUC-PR y visualizaci√≥n de la curva Precision‚ÄìRecall
```{r AUC-PR y Curva Precision-Recall}

library(PRROC)

# Obtener probabilidades para clase positiva "p" (venenoso)
prob_venenoso <- predict(modelo_cv, test_data, type = "prob")$p

# Calcular curva PR
pr_curve <- pr.curve(
  scores.class0 = prob_venenoso[test_data$class == "p"],
  scores.class1 = prob_venenoso[test_data$class == "e"],
  curve = TRUE
)

# Graficar
plot(pr_curve, main = "Curva Precision-Recall ‚Äì Naive Bayes Bernoulli (Test)",

     col = "#2E86C1", lwd = 2,
     auc.main = FALSE)
text(0.5, 0.9, paste("AUC-PR =", round(pr_curve$auc.integral, 3)), 
     cex = 1.2, col = "#2c3e50")


```
<br>

**Interpretaci√≥n Curva Precision-Recall** 

- AUC-PR cercano a 1 ,indica excelente balance entre precisi√≥n y recall para detectar hongos venenosos.

Un AUC-PR de 0.9552 indica que el modelo mantiene un desempe√±o excelente al identificar correctamente la clase ‚Äúvenenoso‚Äù incluso cuando se var√≠a el umbral de probabilidad. 

En t√©rminos pr√°cticos:

1. Alta capacidad para detectar casos realmente venenosos (alto recall),El modelo recupera casi todos los positivos reales a lo largo de distintos umbrales.

2. Mantiene precisi√≥n incluso cuando aumenta el recall,No solo detecta bien, sino que comete muy pocos falsos positivos.

3. La curva es casi plana en la zona superior (precision ‚âà 1 por un amplio rango),Esto es excepcional y refleja un clasificador consistentemente confiable en la clase de inter√©s.


**Conclusi√≥n**

El modelo muestra una capacidad sobresaliente para identificar hongos venenosos, alcanzando un AUC-PR de 0.9552. Esto refleja un equilibrio muy s√≥lido entre precisi√≥n y recall a lo largo de distintos umbrales, con muy pocos falsos positivos y un comportamiento estable. En contextos donde la clase positiva es cr√≠tica, este resultado posiciona al modelo como altamente confiable y operativo.

<br>

## C√°lculo del AUC-ROC y visualizaci√≥n de la curva ROC
```{r AUC-ROC y curva ROC}

library(pROC)

# 1. Obtener probabilidades de la clase positiva "p"
prob_venenoso <- predict(modelo_cv, test_data, type = "prob")$p

# 2. Crear objeto ROC (usando el prefijo pROC:: para evitar conflictos)
roc_obj <- pROC::roc(
  response = test_data$class,
  predictor = prob_venenoso,
  levels = c("e", "p"),
  direction = "<"
)

# 3. Calcular AUC
auc_val <- pROC::auc(roc_obj)

# 4. Graficar la curva ROC 

plot.roc(
  roc_obj,
  main = "Curva ROC -Naive Bayes Bernoulli (test)",
  col = "#2980b9",
  lwd = 3,           # Aqu√≠ se pasa de forma segura a trav√©s del m√©todo espec√≠fico
  grid = TRUE,
  print.auc = FALSE)

# 5. Agregar el texto del AUC manualmente para mayor control est√©tico
text(
  x = 0.4, y = 0.2, 
  labels = paste("AUC-ROC =", round(auc_val, 4)),
  cex = 1.2, 
  col = "#2c3e50",
  font = 2
)

# 6. L√≠nea de referencia (azar)
abline(a = 1, b = -1, lty = 2, col = "red")

```
<br>

**Interpretaci√≥n de la Curva ROC**

***Componentes del gr√°fico:***

- **Curva azul:** Rendimiento del modelo Bernoulli Naive Bayes
- **L√≠nea diagonal gris:** Clasificador aleatorio (sin capacidad predictiva, AUC = 0.5)

Ejes:

- Eje X (1 - Specificity):Tasa de falsos positivos (FPR)
  ‚Üí Proporci√≥n de hongos comestibles clasificados err√≥neamente como venenosos
  
- Eje Y (Sensitivity): Tasa de verdaderos positivos (TPR)  
  ‚Üí Capacidad de identificar correctamente hongos venenosos

**Interpretaci√≥n del gr√°fico:**

La curva se mantiene muy por encima de la diagonal, alcanzando ~95% de sensibilidad con solo ~5% de falsos positivos. Esto indica fuerte capacidad discriminante del modelo al variar el umbral de decisi√≥n.

**AUC-ROC = 0.954:** ,Existe un 95.4% de probabilidad de que el modelo asigne mayor probabilidad de "venenoso" a un hongo realmente venenoso que a uno comestible. esto Implica:

- Excelente separaci√≥n entre clases
- Rendimiento robusto en todo el rango de umbrales
- Consistencia con m√©tricas de matriz de confusi√≥n y curva Precision-Recall

**Punto √≥ptimo:** Esquina superior izquierda (TPR=1,todos los venenosos detectados ; FPR=0 ,sin falsos positivos). El modelo se aproxima notablemente a este ideal.

**Conclusi√≥n:**

El modelo mantiene alto rendimiento independiente del umbral seleccionado, permitiendo ajustar la decisi√≥n seg√∫n prioridad (maximizar detecci√≥n de venenosos vs. minimizar desperdicio de comestibles).

<br>

## Distribuci√≥n de Probabilidades Posteriores por Clase (KDE)
```{r kde-probabilidades-nb, fig.width=14, fig.height=8}

library(ggridges)

# Preparar datos con probabilidades posteriores
prob_df <- data.frame(
  prob_venenoso = predict(modelo_cv, test_data, type="prob")$p,
  prob_comestible = predict(modelo_cv, test_data, type="prob")$e,
  clase_real = test_data$class
)

# Gr√°fico 1: Distribuci√≥n P(venenoso) por clase real
p1 <- ggplot(prob_df, aes(x = prob_venenoso, y = clase_real, fill = clase_real)) +
  geom_density_ridges(
    alpha = 0.7, 
    scale = 2,
    rel_min_height = 0.01,
    quantile_lines = TRUE,
    quantiles = 2
  ) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "black", linewidth = 1.2) +
  annotate("text", x = 0.52, y = 2.5, 
           label = "Umbral\nP=0.5", 
           hjust = 0, size = 4, fontface = "bold") +
  scale_fill_manual(
    values = c("e" = "#8E44AD", "p" = "#F57C00"),
    labels = c("Comestible", "Venenoso")
  ) +
  scale_y_discrete(labels = c("Comestible\n(real)", "Venenoso\n(real)")) +
  labs(
    title = "Distribuci√≥n de P(venenoso) seg√∫n Clase Real",
    subtitle = "Separaci√≥n de probabilidades posteriores - NB Bernoulli",
    x = "P(venenoso | caracter√≠sticas)",
    y = "Clase Real"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
    plot.subtitle = element_text(hjust = 0.5, size = 13),
    legend.position = "none"
  )

p1
```
<br>

**Interpretaci√≥n del KDE (Kernel Density Estimation)**

**Gr√°fico-Ridge Plot:**

Los picos claros y separados confirman la capacidad discriminante del modelo:

- **Pico morado cerca de P‚âà0:** La mayor√≠a de hongos comestibles reciben probabilidades bajas de ser venenosos (modelo confiado en clasificaci√≥n correcta).

- **Pico naranja cerca de P‚âà1:** La mayor√≠a de hongos venenosos reciben probabilidades altas de ser venenosos (modelo confiado en detecci√≥n de toxicidad).

- **L√≠nea vertical negra (P=0.5):** Umbral de decisi√≥n. A la izquierda se clasifica como comestible, a la derecha como venenoso.

<br>

### An√°lisis de separaci√≥n de probabilidades
```{r kde- Estad√≠sticas de separaci√≥n-nb, fig.width=14, fig.height=8}

# Estad√≠sticas de separaci√≥n
cat("\nüìä An√°lisis de separaci√≥n de probabilidades:\n")
cat("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n")

# Para comestibles reales
prob_comestibles <- prob_df %>% filter(clase_real == "e") %>% pull(prob_venenoso)
cat("Hongos comestibles reales:\n")
cat("  ‚Ä¢ P(venenoso) media:", round(mean(prob_comestibles), 4), "\n")
cat("  ‚Ä¢ P(venenoso) mediana:", round(median(prob_comestibles), 4), "\n")
cat("  ‚Ä¢ Desv. est√°ndar:", round(sd(prob_comestibles), 4), "\n\n")

# Para venenosos reales
prob_venenosos <- prob_df %>% filter(clase_real == "p") %>% pull(prob_venenoso)
cat("Hongos venenosos reales:\n")
cat("  ‚Ä¢ P(venenoso) media:", round(mean(prob_venenosos), 4), "\n")
cat("  ‚Ä¢ P(venenoso) mediana:", round(median(prob_venenosos), 4), "\n")
cat("  ‚Ä¢ Desv. est√°ndar:", round(sd(prob_venenosos), 4), "\n\n")

# Cuantificar solapamiento
zona_incierta <- prob_df %>%
  filter(prob_venenoso >= 0.4 & prob_venenoso <= 0.6)

cat("üî∂ Zona de incertidumbre (0.4 ‚â§ P ‚â§ 0.6):\n")
cat("  ‚Ä¢ Casos totales:", nrow(zona_incierta), 
    sprintf("(%.2f%% del test set)\n", (nrow(zona_incierta)/nrow(prob_df))*100))
cat("  ‚Ä¢ Comestibles en zona incierta:", sum(zona_incierta$clase_real == "e"), "\n")
cat("  ‚Ä¢ Venenosos en zona incierta:", sum(zona_incierta$clase_real == "p"), "\n")
```
<br>

**Conclusi√≥n**

El modelo demuestra una separaci√≥n perfecta y absoluta de las clases, con un 0.00% de casos en la zona de incertidumbre. Al obtener medianas de probabilidad de 0 para comestibles y 1 para venenosos, el algoritmo no solo clasifica correctamente, sino que lo hace con certeza total, eliminando cualquier ambig√ºedad en la identificaci√≥n de toxicidad.

<br>

## An√°lisis de Separabilidad Multivariante: Top 6 Predictores
```{r comparacion-fronteras-nb-knn-lado-a-lado, fig.width=18, fig.height=8}

# Obtener top 6 variables
importancia <- varImp(modelo_cv)
top6_vars <- rownames(head(
  importancia$importance[order(-importancia$importance[,1]), , drop=FALSE], 
  6
))

# Preparar datos para ggpairs
datos_ggpairs <- train_data[, c(top6_vars, "class")] %>%
  mutate(across(all_of(top6_vars), as.numeric)) %>%
  mutate(class = factor(class, labels = c("Comestible", "Venenoso")))

# Nombres compactos
nombres_legibles <- c("Olor\nAus.", "Olor\nF√©t.", 
                      "Tallo\nSup.", "Tipo\nAnillo",
                      "Tallo\nInf.", "Magull.", "Clase")

# Crear ggpairs con mayor espacio vertical
ggpairs(
  datos_ggpairs,
  aes(color = class, alpha = 0.6),
  
  # Tri√°ngulo superior: correlaciones por clase
  upper = list(
    continuous = wrap("cor", 
                     size = 5.5,        # Tama√±o moderado
                     stars = FALSE,
                     color="black",
                     alignPercent = 0.5)
  ),
  
  # Tri√°ngulo inferior: dispersi√≥n
  lower = list(
    continuous = wrap("points", 
                     alpha = 0.3,
                     size = 0.8,
                     position = position_jitter(width = 0.1, height = 0.1))
  ),
  
  # Diagonal: densidades
  diag = list(
    continuous = wrap("densityDiag", 
                     alpha = 0.6,
                     bw = "SJ")
  ),
  
  columnLabels = nombres_legibles,
  title = "Matriz de Separabilidad: Top 6 Variables M√°s Discriminantes"
) +
  scale_fill_manual(values = c("Comestible" = "#8E44AD", "Venenoso" = "#F57C00")) +
  scale_color_manual(values = c("Comestible" = "#8E44AD", "Venenoso" = "#F57C00")) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 20, margin = margin(b = 12)),
    
    strip.text.x = element_text(size = 16, face = "bold", lineheight = 0.85, margin = margin(t = 2, b = 2)),
    strip.text.y = element_text(size = 16, face = "bold", lineheight = 0.85, margin = margin(l = 2, r = 2)),
    
    strip.background = element_rect(fill = "grey92", color = "grey75"),
    
    axis.text.x = element_text(size = 14, angle = 45, hjust = 1, vjust = 1),
    axis.text.y = element_text(size = 10),
    
    legend.position = "bottom",
    legend.text = element_text(size = 20),
    legend.title = element_text(size = 12, face = "bold"),
    
    panel.spacing = unit(0.6, "lines"),  # M√°s espacio entre paneles
    plot.margin = margin(t = 12, r = 12, b = 12, l = 12)
  )

```


**Interpretaci√≥n de la Matriz de Separabilidad**

La matriz ggpairs eval√∫a las seis variables m√°s discriminantes desde tres perspectivas complementarias que revelan tanto fortalezas como limitaciones del modelo Bernoulli Naive Bayes.

**Diagonal: Poder discriminante individual**

Los gr√°ficos de densidad muestran que variables como `odor_n` exhiben separaci√≥n bimodal clara entre clases: picos naranjas y morados en valores distintos indican alto poder predictivo individual. Sin embargo, trat√°ndose de variables binarias {0,1}, esta "separaci√≥n" representa diferencias en proporciones por clase, no distribuciones continuas desplazadas.

**Tri√°ngulo inferior: Estructura discreta**

Los diagramas de dispersi√≥n revelan la naturaleza categ√≥rica subyacente. Las observaciones reales ocupan solo cuatro posiciones: (0,0), (0,1), (1,0), (1,1). El jitter es artefacto visual para evitar solapamiento. Los "cl√∫steres de color" indican frecuencias relativas, no reglas determin√≠sticas: color predominante naranja en (0,1) significa que en esa combinaci√≥n la mayor√≠a son hongos venenosos, pero no necesariamente el 100%.

**Tri√°ngulo superior: Violaci√≥n cr√≠tica del supuesto de independencia**

Cada celda muestra tres correlaciones: global (Corr), condicional en comestibles, y condicional en venenosos. El supuesto de Naive Bayes requiere que las correlaciones **condicionales dentro de cada clase** sean cercanas a cero. Los datos refutan este supuesto:

- **Violaci√≥n moderada**: `odor_n` vs `odor_f` en venenosos: -0.203 (los tipos de olor no son independientes)
- **Violaci√≥n severa**: `ring_type_p` vs `stalk_surface_below_ring_k` en venenosos: 0.529 (tipo de anillo y textura de tallo est√°n fuertemente correlacionados)
- **Violaci√≥n cr√≠tica**: `bruises_t` vs `stalk_surface_below_ring_k`: 0.591 en comestibles y 0.848 en venenosos (magulladuras y textura del tallo capturan aspectos relacionados de la morfolog√≠a)

**Implicaci√≥n directa**: Estas correlaciones altas explican los **51 falsos negativos** del modelo. Combinaciones espec√≠ficas de caracter√≠sticas que conjuntamente indican toxicidad no pueden ser capturadas por un modelo que eval√∫a cada variable aisladamente. La independencia condicional asumida es incorrecta, causando que el modelo ignore interacciones cr√≠ticas entre atributos morfol√≥gicos.

**Conclusi√≥n**: El modelo alcanza 94.09% accuracy **a pesar de** violar severamente el supuesto de independencia, no porque lo cumpla. Las variables individuales son suficientemente discriminantes para compensar parcialmente esta violaci√≥n, pero los errores cr√≠ticos ocurren precisamente en casos donde las interacciones entre variables son determinantes para la clasificaci√≥n correcta.

> **Nota t√©cnica**: La matriz no valida el uso de Bernoulli NB; al contrario, documenta emp√≠ricamente por qu√© este modelo es sub√≥ptimo para este problema. El contraste con KNN (0 errores) confirma que la estructura de dependencias en el espacio de 111 variables contiene informaci√≥n cr√≠tica que Naive Bayes no puede aprovechar bajo su marco simplificado.

<br>

## Frontera de decisi√≥n con gradiente de confianza -Naive Bayes Bernoulli
```{r linea-decision-bernoulli-gradiente, fig.width=12, fig.height=9}

library(ggplot2)

# Obtener top 2 variables del modelo CV
importancia <- varImp(modelo_cv)
top2 <- rownames(head(importancia$importance[
  order(-importancia$importance[,1]), , drop=FALSE], 2))

# Preparar datos con jitter
data_viz <- train_data[, c(top2, "class")]
colnames(data_viz)[1:2] <- c("X1", "X2")
data_viz$X1_jitter <- jitter(data_viz$X1, factor=2)
data_viz$X2_jitter <- jitter(data_viz$X2, factor=2)

# Grid de predicci√≥n CONTINUO (sin redondear)
grid <- expand.grid(
  X1 = seq(-0.3, 1.3, length.out=300),
  X2 = seq(-0.3, 1.3, length.out=300)
)

# Crear datos para predicci√≥n
grid_pred_data <- as.data.frame(matrix(0, nrow=nrow(grid), ncol=ncol(train_data)-1))
colnames(grid_pred_data) <- setdiff(names(train_data), "class")

# ‚ö†Ô∏è CR√çTICO: NO REDONDEAR para mantener gradiente
grid_pred_data[, top2[1]] <- grid$X1  # Sin round()
grid_pred_data[, top2[2]] <- grid$X2  # Sin round()

# Predicciones con probabilidades
grid_probs <- predict(modelo_cv, newdata=grid_pred_data, type="prob")
grid$prob_venenoso <- grid_probs$p
grid$pred <- ifelse(grid$prob_venenoso > 0.5, "p", "e")

# Gr√°fico con gradiente de confianza
ggplot() +
  # Fondo con gradiente de probabilidad
  geom_tile(data=grid, aes(X1, X2, fill=prob_venenoso), alpha=0.95) +
  
  # Contorno P(venenoso) = 0.5 (frontera de decisi√≥n)
  geom_contour(data=grid, aes(X1, X2, z=prob_venenoso), 
               breaks=0.5, color="black", linewidth=1.5) +
  
  # Puntos reales con jitter
  geom_point(data=data_viz, aes(X1_jitter, X2_jitter, color=class), 
             size=2, alpha=0.7) +
  
  # Gradiente de color (3 colores)
  scale_fill_gradient2(
    low = "#8E44AD",      # Comestible seguro (P‚âà0)
    mid = "#FFEB3B",      # Zona incierta (P‚âà0.5)
    high = "#F57C00",     # Venenoso seguro (P‚âà1)
    midpoint = 0.5,
    limits = c(0, 1),
    name = "P(venenoso)"
  ) +
  
  scale_color_manual(
    values = c("e" = "#6c3483", "p" = "#c0392b"),
    name = "Clase Real"
  ) +
  
  labs(
    title = "Frontera de Decisi√≥n con Gradiente de Confianza",
    subtitle = paste("Naive Bayes Bernoulli -", top2[1], "vs", top2[2]),
    x = top2[1], 
    y = top2[2]
  ) +
  
  theme_minimal(base_size=14) +
  theme(
    plot.title = element_text(hjust=0.5, face="bold", size=16),
    plot.subtitle = element_text(hjust=0.5, size=12),
    legend.position = "right",
    legend.title = element_text(size=12, face="bold"),
    legend.text = element_text(size=10)
  )
```
<br>

**Interpretaci√≥n del Gradiente de Confianza**

El gradiente de color identifica tres zonas diferenciadas en el espacio de decisi√≥n del clasificador Naive Bayes Bernoulli. La zona morada, correspondiente a probabilidades entre 0.00 y 0.25, representa regiones donde el modelo asigna alta confianza a la clasificaci√≥n como hongos comestibles, con certeza superior al 75%. La zona intermedia en tonos m√°s claros, donde las probabilidades oscilan entre 0.40 y 0.60, constituye la regi√≥n de incertidumbre cr√≠tica del modelo. En esta √°rea, el clasificador presenta dificultades para discriminar entre clases, distribuyendo la probabilidad de manera pr√°cticamente equitativa. Las observaciones que caen en esta zona requieren validaci√≥n adicional mediante criterios expertos o m√©todos complementarios de clasificaci√≥n. La zona naranja, asociada a probabilidades entre 0.75 y 1.00, indica alta confianza en la clasificaci√≥n como hongos venenosos, respaldada por evidencia probabil√≠stica sustancial derivada de los patrones de entrenamiento.

La frontera de decisi√≥n, representada mediante la l√≠nea negra horizontal en odor.f = 0.5, establece el umbral formal de clasificaci√≥n donde la probabilidad posterior P(venenoso) = 0.50. Las observaciones sobre este umbral son clasificadas como venenosas, mientras que aquellas por debajo se clasifican como comestibles seg√∫n el criterio de m√°xima probabilidad posterior.

Es relevante destacar que, aunque las variables predictoras odor.n y odor.f son inherentemente binarias con valores en {0,1}, el modelo genera probabilidades continuas en el espacio bidimensional. Este gradiente continuo refleja la manera en que el clasificador Naive Bayes interpola probabilidades considerando la combinaci√≥n de caracter√≠sticas observadas, revelando as√≠ la estructura probabil√≠stica subyacente del problema de clasificaci√≥n y las regiones donde la discriminaci√≥n entre clases resulta m√°s o menos confiable seg√∫n la evidencia disponible en los datos de entrenamiento.

<br>

# An√°lisis en test set
## Dataset con predicciones e interpretaci√≥n
```{r Dataset con predicciones}

library(kableExtra)

# Asegurar que pred_todo existe
if(!exists("pred_clasificacion")) {
  pred_clasificacion <- predict(modelo_cv, test_data)
}

# Crear dataset con predicciones mejoradas
data_pred <- test_data %>%
  mutate(
    Clase_Real = class,
    Clase_Predicha = pred_clasificacion,
    Interpretacion = case_when(
      Clase_Predicha == "e" ~ "üçÑ Comestible",
      Clase_Predicha == "p" ~ "‚ò†Ô∏è Venenoso"
    ),
    Correcto = ifelse(Clase_Real == Clase_Predicha, "‚úÖ Correcto", "‚ùå Error")
  )

# Mostrar ejemplos con kable 
kable(
  head(data_pred[, c("Clase_Real", "Clase_Predicha", "Interpretacion", "Correcto")], 10),
  col.names = c("Clase Real", "Clase Predicha", "Interpretaci√≥n", "Resultado"),
  align = c("c", "c", "l", "c"),
  caption = "Primeras 10 predicciones del modelo"
)

# Resumen de aciertos
cat("  Total de predicciones:", nrow(data_pred), "\n")
cat("  Predicciones correctas:", sum(data_pred$Clase_Real == data_pred$Clase_Predicha), 
    sprintf("(%.2f%%)\n", mean(data_pred$Clase_Real == data_pred$Clase_Predicha)*100))
cat("  Predicciones incorrectas:", sum(data_pred$Clase_Real != data_pred$Clase_Predicha),
    sprintf("(%.2f%%)\n", mean(data_pred$Clase_Real != data_pred$Clase_Predicha)*100))


```

## Interpretaci√≥n de Resultados
```{r Interpretaci√≥n de Resultados}

# An√°lisis de predicciones finales

total_pred <- table(pred_clasificacion)
clase_mayoritaria <- names(which.max(total_pred))
porcentaje_mayor <- max(prop.table(total_pred)) * 100

cat("\nüéØ Resultado final del modelo:\n")


if(clase_mayoritaria == "e") {
  cat("‚úÖ La mayor√≠a de hongos son predichos como COMESTIBLES\n")
  cat("   - Comestibles:", total_pred["e"], "hongos (", round(porcentaje_mayor, 1), "%)\n")
  cat("   - Venenosos:", total_pred["p"], "hongos (", round((1-max(prop.table(total_pred)))*100, 1), "%)\n")
} else {
  cat("‚ö†Ô∏è La mayor√≠a de hongos son predichos como VENENOSOS\n")
  cat("   - Venenosos:", total_pred["p"], "hongos (", round(porcentaje_mayor, 1), "%)\n")
  cat("   - Comestibles:", total_pred["e"], "hongos (", round((1-max(prop.table(total_pred)))*100, 1), "%)\n")
}

# Comparaci√≥n con datos reales
real_dist <- prop.table(table(test_data$class)) * 100
cat("\nüìä Distribuci√≥n real en test set:\n")
cat("   - Comestibles:", round(real_dist["e"], 1), "%\n")
cat("   - Venenosos:", round(real_dist["p"], 1), "%\n")

```

**Interpretaci√≥n**

El modelo predice **ligeramente m√°s hongos como comestibles que venenosos**, con una diferencia marginal de unos 4 puntos porcentuales. Esto indica que, en promedio, el modelo tiende a clasificar los casos de forma bastante equilibrada entre ambas categor√≠as y no muestra una inclinaci√≥n fuerte hacia ninguna clase.

La proximidad entre las proporciones predichas y las proporciones reales sugiere que el modelo est√° capturando bien la estructura general del conjunto de datos. Sin embargo, ***dado que la diferencia entre clases es peque√±a, esta predominancia de hongos ‚Äúcomestibles‚Äù debe interpretarse con cautela***, ya que no representa una ventaja decisiva de una clase sobre la otra.

**Conclusi√≥n**

S√≠, seg√∫n las predicciones, la clase que aparece con mayor frecuencia es "comestible".
Pero la diferencia es tan estrecha que no se puede afirmar con alta confianza que un nuevo hongo ser√° comestible solo porque la mayor√≠a predicha cae en esa categor√≠a.


***‚ÄúEl modelo predice una ligera mayor presencia de hongos comestibles, pero las clases est√°n pr√°cticamente equilibradas.‚Äù***

<br>

# Validar si hongos son comestible o venenosa
## Matriz de confusi√≥n
```{r Matriz de confusi√≥n e}

conf <- confusionMatrix(
  factor(pred_clasificacion, levels = c("e", "p")),
  factor(test_data$class, levels = c("e", "p"))
)
conf

```
<br>

**Interpretaci√≥n de la Matriz de Confusi√≥n: Bernoulli Naive Bayes**

El modelo presenta un desempe√±o s√≥lido con una **Exactitud (Accuracy) del 94.09%**, superando significativamente la tasa de informaci√≥n de referencia (51.79%). El √≠ndice **Kappa de 0.8816** confirma un acuerdo "excelente" entre las predicciones y las clases reales, m√°s all√° del azar.

***An√°lisis de Errores y Seguridad (Cr√≠tico)***
En el contexto de la clasificaci√≥n de hongos, el costo de los errores es asim√©trico. Analizamos los dos tipos de fallos presentes:

1. **Falsos Negativos de Toxicidad (51 casos):** El modelo clasific√≥ como **"Comestibles" (e)** a 51 hongos que en realidad eran **"Venenosos" (p)**. Este es el error m√°s cr√≠tico, ya que en un escenario real representar√≠a un riesgo directo para la salud.

2. **Falsos Positivos de Toxicidad (45 casos):** El modelo etiquet√≥ como **"Venenosos"** a 45 espec√≠menes **"Comestibles"**. Aunque es un error, es un fallo "seguro" desde el punto de vista preventivo, pues solo implica el desperdicio de alimento seguro.

**M√©tricas de Diagn√≥stico**

* **Sensibilidad (Recall - Comestibles): 94.65%** ‚Äì Capacidad del modelo para identificar correctamente los hongos seguros.
* **Especificidad (Recall - Venenosos): 93.49%** ‚Äì Capacidad del modelo para detectar correctamente los hongos t√≥xicos.
* **Test de McNemar (p-value = 0.6098):** Al ser mayor a 0.05, indica que no existe una asimetr√≠a significativa en el tipo de errores; es decir, el modelo se equivoca en proporciones similares para ambas clases.

> **Conclusi√≥n:** Aunque el modelo alcanza una precisi√≥n muy alta (~94%), la presencia de **51 falsos negativos** sugiere que, si bien el algoritmo es √∫til como herramienta de filtrado inicial, los supuestos de independencia de Naive Bayes podr√≠an estar limitando la detecci√≥n de interacciones complejas necesarias para alcanzar el 100% de seguridad requerido en este dominio.

## Evaluaci√≥n de m√©tricas por clase y an√°lisis comparativo
```{r Evaluaci√≥n de M√©tricas por Clase y An√°lisis Comparativo}

# 1. Matriz de confusi√≥n para cada clase
conf_comestible <- confusionMatrix(
  factor(pred_clasificacion, levels = c("e", "p")),
  factor(test_data$class, levels = c("e", "p")),
  positive = "e"
)

conf_venenoso <- confusionMatrix(
  factor(pred_clasificacion, levels = c("e", "p")),
  factor(test_data$class, levels = c("e", "p")),
  positive = "p"
)

# 2. Extraer m√©tricas clave
metricas_por_clase <- data.frame(
  Clase = c("Comestible (e)", "Venenoso (p)"),
  Sensitivity = c(
    conf_comestible$byClass["Sensitivity"],
    conf_venenoso$byClass["Sensitivity"]
  ),
  Specificity = c(
    conf_comestible$byClass["Specificity"],
    conf_venenoso$byClass["Specificity"]
  ),
  F1_Score = c(
    conf_comestible$byClass["F1"],
    conf_venenoso$byClass["F1"]
  ),
  Precision = c(
    conf_comestible$byClass["Pos Pred Value"],
    conf_venenoso$byClass["Pos Pred Value"]
  )
)

# 3. Mostrar tabla comparativa

kable(
  metricas_por_clase,
  digits = 4,
  col.names = c("Clase", "Recall (Sensibilidad)", "Especificidad", "F1-Score", "Precisi√≥n"),
  align = c("l", "c", "c", "c", "c")
)

cat("\nüìã Lectura de la tabla:\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
cat("Cada fila cambia cu√°l clase es 'positiva':\n\n")
cat("‚Ä¢ Fila 1 (e=positiva): Recall=detecci√≥n de comestibles | Specificity=detecci√≥n de venenosos\n")
cat("‚Ä¢ Fila 2 (p=positiva): Recall=detecci√≥n de venenosos | Specificity=detecci√≥n de comestibles\n")
cat("\nObserva: Los valores se 'intercambian' entre Recall y Specificity seg√∫n la clase de referencia.\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")

# 4. An√°lisis de diferencias
cat("\n\nüîç An√°lisis comparativo:\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
cat("  Diferencia en Recall:", 
    sprintf("%.4f", abs(metricas_por_clase$Sensitivity[1] - metricas_por_clase$Sensitivity[2])),
    ifelse(abs(metricas_por_clase$Sensitivity[1] - metricas_por_clase$Sensitivity[2]) < 0.02,
           "(Equilibrado ‚úÖ)", "(Desbalanceado ‚ö†Ô∏è)"), "\n")
cat("  Diferencia en F1-Score:", 
    sprintf("%.4f", abs(metricas_por_clase$F1_Score[1] - metricas_por_clase$F1_Score[2])),
    ifelse(abs(metricas_por_clase$F1_Score[1] - metricas_por_clase$F1_Score[2]) < 0.01,
           "(Equilibrado ‚úÖ)", "(Desbalanceado ‚ö†Ô∏è)"), "\n")

# 5. Balanced Accuracy
bal_acc <- conf_comestible$byClass["Balanced Accuracy"]
cat("\n  Balanced Accuracy:", round(bal_acc, 4), "\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")

# 6. Interpretaci√≥n cr√≠tica
cat("\nüí° Interpretaci√≥n:\n")
if(metricas_por_clase$Sensitivity[2] < 0.95) {
  cat("  ‚ö†Ô∏è El Recall de venenosos (", round(metricas_por_clase$Sensitivity[2], 4), 
      ") indica que ~", round((1-metricas_por_clase$Sensitivity[2])*100, 1),
      "% de hongos venenosos NO son detectados (RIESGO CR√çTICO)\n")
} else {
  cat("  ‚úÖ El modelo detecta correctamente >95% de hongos venenosos\n")
}

```
## Visualizaci√≥n comparaci√≥n entre clases reales y predichas
```{r plot comparacion entre clases reales-predichas}

# 1. Preparar datos para visualizaci√≥n
resultados_plot <- data.frame(
  Real = test_data$class,
  Predicha = pred_clasificacion
)

# 2. Gr√°fico de distribuci√≥n
ggplot(resultados_plot, aes(x = Real, fill = Predicha)) +
  geom_bar(position = "dodge", alpha = 0.8) +
  geom_text(
    stat = 'count',
    aes(label = after_stat(count)),
    position = position_dodge(width = 0.9),
    vjust = -0.5,
    size = 4
  ) +
  labs(
    title = "Comparaci√≥n entre Clases Reales y Predichas",
    subtitle = paste0("Test Set (n = ", nrow(test_data), ")"),
    x = "Clase Real",
    y = "Frecuencia",
    fill = "Clase Predicha"
  ) +
  scale_fill_manual(
    values = c("e" = "#9b59b6", "p" = "#F57C00"),
    labels = c("Comestible", "Venenoso")
  ) +
  scale_x_discrete(labels = c("Comestible\n(e)", "Venenoso\n(p)")) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    legend.position = "top"
  )
```

<br>

**Interpretaci√≥n del Gr√°fico: Comparaci√≥n entre Clases Reales y Predichas**

1. Clase Real: Comestible (e)

- 796 hongos comestibles fueron correctamente clasificados como comestibles (barra morada alta).

- 45 hongos comestibles fueron err√≥neamente clasificados como venenosos (barra naranja baja).

Interpretaci√≥n:

El modelo tiene una alta precisi√≥n al identificar hongos comestibles.
Los falsos positivos (comestible ‚Üí venenoso) son pocos y, si bien representan un error, son seguros desde la perspectiva del riesgo (implican desperdicio, no da√±o).

2. Clase Real: Venenoso (p)

- 732 hongos venenosos fueron correctamente clasificados como venenosos (barra naranja alta).

- 51 hongos venenosos fueron clasificados como comestibles (barra morada baja).

Interpretaci√≥n:

Aqu√≠ el gr√°fico revela el punto m√°s cr√≠tico:
Los 51 falsos negativos (venenoso ‚Üí comestible) representan riesgo severo, porque son casos donde el modelo ‚Äúdeja pasar‚Äù hongos peligrosos como si fueran seguros.

3. Lectura global del gr√°fico

Las barras moradas y naranjas altas muestran que el modelo tiene un alto poder de clasificaci√≥n correcta en ambas clases.

Las barras bajas permiten apreciar visualmente la magnitud de los errores.

El gr√°fico confirma lo observado en la matriz de confusi√≥n:

- Alto rendimiento general

- Errores bien distribuidos

- Pero con especial atenci√≥n al falso negativo venenoso.

**Conclusi√≥n**

El gr√°fico permite visualizar con claridad la relaci√≥n entre predicci√≥n y realidad: el modelo distingue de manera consistente entre hongos comestibles y venenosos, pero tambi√©n evidencia los errores cr√≠ticos. La diferencia en la altura de las barras refuerza que el desempe√±o global es s√≥lido; sin embargo, los 51 falsos negativos marcan una alerta importante que debe considerarse al evaluar la seguridad del modelo en aplicaciones reales.

## Importancia de variables - Naive Bayes Bernoulli
```{r importancia-variables-NB-corregido, fig.width=12, fig.height=8}

# Extraer importancia de forma segura
importancia_nb <- varImp(modelo_cv)

# Forzar a data frame y extraer la columna correcta (puede llamarse "Overall" o ser la primera)
imp_raw <- importancia_nb$importance

# Si es un data.frame con una sola columna sin nombre o con nombre raro:
if(is.null(colnames(imp_raw)) || !("Overall" %in% colnames(imp_raw))) {
  imp_df <- data.frame(Overall = imp_raw[, 1], row.names = rownames(imp_raw))
} else {
  imp_df <- imp_raw
}

# A√±adir nombres de variables
imp_df$Variable <- rownames(imp_df)

# Ordenar de mayor a menor importancia
imp_df <- imp_df[order(-imp_df$Overall), ]

# Convertir Variable a factor ordenado (para ggplot)
imp_df$Variable <- factor(imp_df$Variable, levels = rev(imp_df$Variable))

# Top 20
top_n <- 20
imp_top <- head(imp_df, top_n)

# Colores
colores_nb <- c(
  "#54278f",  # Morado profundo
  "#756bb1",  # Lavanda/morado claro
  "#3182bd",  # Azul fuerte
  "#6baed6",  # Azul claro
  "#2ca25f",  # Verde intenso
  "#66c2a4",  # Verde agua
  "#1b9e77",  # Verde azulado contrastado
  "#80cdc1"   # Turquesa claro
)

# Gr√°fico (ahora S√ç funciona)
ggplot(imp_top, aes(x = Overall, y = Variable, fill = Overall)) +
  geom_col(width = 0.8, alpha = 0.9) +
  geom_text(aes(label = round(Overall, 2)), 
            hjust = -0.2, size = 3.8, fontface = "bold", color = "white") +
  scale_fill_gradientn(colors = colores_nb, name = "Importancia") +
  labs(
    title = "Top 20 Variables M√°s Importantes - Naive Bayes Bernoulli",
    subtitle = "Importancia basada en diferencia absoluta de log-probabilidades condicionales",
    x = "Importancia (mayor = m√°s discriminante)",
    y = ""
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16, color = "#2c3e50"),
    plot.subtitle = element_text(hjust = 0.5, size = 13, color = "#7f8c8d"),
    axis.text.y = element_text(size = 11, color = "black", face = "plain"),
    legend.position = "none",
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank(),
    plot.margin = margin(20, 40, 20, 20)
  ) +
  coord_cartesian(xlim = c(0, max(imp_df$Overall) * 1.15))
```
<br>

### Importancia de Variables: Top 5
```{r importancia-variable Mostrar top 5,echo=FALSE}

cat(
  "\nTop 5 variables m√°s importantes (Bernoulli NB):\n\n",
  paste(sprintf("  - %s: %.4f", imp_df$Variable[1:5],  imp_df$Overall[1:5]),
    collapse = "\n"),"\n")

```

### Interpretaci√≥n
```{r Interpretaci√≥n, echo=FALSE}

cat("\nüí° INTERPRETACI√ìN:\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
cat("En Bernoulli Naive Bayes, la 'importancia' refleja cu√°nto\n")
cat("cada variable binaria contribuye a diferenciar las clases.\n")
cat("\nVariables con mayor importancia:\n")
cat("  ‚Üí Tienen distribuciones muy diferentes entre comestibles y venenosos\n")
cat("  ‚Üí Son las m√°s √∫tiles para la clasificaci√≥n\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")

# Refrescar y ordenar correctamente
importancia <- varImp(modelo_cv)
top_vars <- head(importancia$importance[order(-importancia$importance[,1]), , drop = FALSE], 5)

cat("\nüèÜ TOP 5 VARIABLES M√ÅS DISCRIMINANTES:\n")
for(i in 1:5) {
  cat("  ", i, ". ", rownames(top_vars)[i], 
      " (Importancia: ", round(top_vars[i, 1], 2), ")\n", sep = "")
}

```

<br>

**Top 5 Variables M√°s Discriminantes en Bernoulli Naive Bayes**

En Bernoulli Naive Bayes, la importancia de cada variable refleja cu√°nto contribuye a diferenciar entre clases (comestibles vs. venenosos). A continuaci√≥n se describen las cinco variables m√°s discriminantes seg√∫n el modelo:

**odor.n (Importancia: 100)**

   * Representa la presencia del olor *n* (ej. ‚Äúalmizcle‚Äù) en el hongo.
   * Es la variable m√°s poderosa para distinguir hongos comestibles de venenosos, ya que su distribuci√≥n difiere significativamente entre las clases.


**odor.f (Importancia: 70.72)**

   * Indica la presencia del olor *f* (ej. ‚Äúalmendra‚Äù).
   * Contribuye de manera muy alta a la clasificaci√≥n, mostrando patrones claros que ayudan al modelo a separar clases.


**stalk_surface_above_ring.k (Importancia: 69.78)**

   * Describe la textura de la superficie del tallo **por encima del anillo**, con categor√≠a *k* (ej. ‚Äúescamosa‚Äù).
   * Las diferencias en esta caracter√≠stica son √∫tiles para identificar hongos venenosos frente a comestibles.


**ring_type.p (Importancia: 68.74)**

   * Se√±ala el tipo de anillo en el tallo, espec√≠ficamente la categor√≠a *p* (ej. ‚Äúpendiente‚Äù).
   * Permite al modelo reforzar la separaci√≥n de clases seg√∫n la presencia o ausencia de este tipo de anillo.


**stalk_surface_below_ring.k (Importancia: 67.73)**

   * Describe la textura de la superficie del tallo **debajo del anillo**, con categor√≠a *k* (‚Äúescamosa‚Äù).
   * Al igual que su contraparte sobre el anillo, ayuda a diferenciar los hongos venenosos de los comestibles.

üí° Observaci√≥n: Variables con mayor importancia tienen distribuciones muy diferentes entre las clases y son las m√°s √∫tiles para la clasificaci√≥n.


# **Predicci√≥n con Naive Bayes Bernoulli(nuevos datos)**
```{r Predicci√≥n con Bernoulli Naive Bayes(nuevos datos)}

set.seed(456)

nuevo_hongo <- test_data[sample(nrow(test_data), 15), ]
pred_nuevos <- predict(modelo_cv, nuevo_hongo, type = "prob")

resultados <- data.frame(
  Real = nuevo_hongo$class,
  Predicho = predict(modelo_cv, nuevo_hongo),
  Prob_Comestible = round(pred_nuevos$e, 3),
  Prob_Venenoso = round(pred_nuevos$p, 3)
)
print(resultados)

# INTERPRETACI√ìN INDIVIDUAl
for(i in 1:nrow(resultados)) {
  
  cat("\nüçÑ Hongo", i, "(Bernoulli NB):\n")
  
  prob_max <- max(resultados$Prob_Comestible[i], resultados$Prob_Venenoso[i])
  clase_final <- ifelse(resultados$Predicho[i] == "e", "COMESTIBLE", "VENENOSO")
  
  cat("‚Üí Clasificaci√≥n final:", clase_final, "\n")
  cat("‚Üí Probabilidad asignada:", prob_max, "\n")
  cat("‚Üí Probabilidad Comestible:", resultados$Prob_Comestible[i], "\n")
  cat("‚Üí Probabilidad Venenoso:", resultados$Prob_Venenoso[i], "\n")
  cat("‚Üí Clase real:", ifelse(resultados$Real[i] == "e", "Comestible", "Venenoso"), "\n")
}

cat("\nüéØ Modelo: Bernoulli Naive Bayes\n")
cat("‚Ä¢ La 'clasificaci√≥n final' corresponde a la clase con mayor probabilidad\n")
cat("‚Ä¢ Cada probabilidad indica la confianza del modelo en su decisi√≥n\n")

cat("\nüìä RESUMEN DE VALIDACI√ìN:\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
cat("  Predicciones correctas: ", sum(resultados$Real == resultados$Predicho), "/15\n")
cat("  Accuracy en muestra: ", round(mean(resultados$Real == resultados$Predicho)*100, 1), "%\n")
cat("\nüí° Nota: Probabilidades extremas (0/1) indican alta confianza del modelo\n")
cat("  en estas instancias particulares del test set.\n")

```

# Algoritmo K-Nearest Neighbors (KNN) 
## Resumen del Dataset
```{r Paso 1: Preparar los datos}

# recordar c√≥mo est√°n estructurados

cat("Datos de entrenamiento:", nrow(train_data), "hongos\n")
cat("Datos de prueba:", nrow(test_data), "hongos\n")
cat("Total de variables predictoras:", ncol(train_data)-1, "(todas binarias)\n")

```

## Preparaci√≥n de datos para k-NN: separaci√≥n de predictores y variable objetivo
```{r Paso 2: Implementaci√≥n manual de KNN}

library(class) 

# Separamos predictores y etiqueta
X_train <- train_data[, -which(names(train_data) == "class")]
y_train <- train_data$class

X_test  <- test_data[,  -which(names(test_data)  == "class")]
y_test  <- test_data$class

```

<br>

## Funcionamiento Interno del Algoritmo k-NN

Para cada hongo del conjunto de prueba, el algoritmo ejecuta:

1. **C√°lculo de distancia euclidiana** a los 6,500 hongos de entrenamiento:
$$d = \sqrt{\sum_{i=1}^{111}(x_i - y_i)^2}$$

2. **Ordenamiento** de distancias de menor a mayor

3. **Selecci√≥n** de los k vecinos m√°s cercanos

4. **Voto por mayor√≠a**: asigna la clase m√°s frecuente entre esos k vecinos

Este proceso se repite para cada uno de los 1,624 hongos del test set, lo que implica $1,624 \times 6,500 = 10,556,000$ c√°lculos de distancia por predicci√≥n completa.

<br>

## B√∫squeda Exhaustiva del k √ìptimo en k-NN (manual grid search)
```{r Paso 3: Buscar autom√°ticamente el mejor valor de k}

set.seed(123)

# Probar k de 1 hasta 25 (m√°s que suficiente para este dataset)
k_candidatos <- 1:25
accuracy_k <- numeric(length(k_candidatos))

for(k in k_candidatos) {
  pred <- knn(train = X_train,
              test  = X_test,
              cl    = y_train,
              k     = k)
  
  accuracy_k[k] <- mean(pred == y_test)
}

# Mejor k encontrado
k_optimo <- which.max(accuracy_k)
acc_optimo <- accuracy_k[k_optimo]

cat("Resultado de la b√∫squeda autom√°tica de k:\n")
cat("k √≥ptimo =", k_optimo, "‚Üí Accuracy =", round(acc_optimo, 5), "\n")
```


## Visualizaci√≥n gr√°fico de evoluci√≥n del accuracy seg√∫n k
```{r Paso 4: Gr√°fico de evoluci√≥n del accuracy seg√∫n k, fig.width = 12,fig.height = 6}

# Crear data frame
df_k <- data.frame(
  k = k_candidatos,
  accuracy = accuracy_k
)

# Rango seguro del eje Y
y_min <- min(accuracy_k) - 0.01
y_max <- max(accuracy_k) + 0.01

ggplot(df_k, aes(x = k, y = accuracy)) +
  geom_line(color = "#2E86C1", linewidth = 1.3) +
  geom_point(color = "#2E86C1", size = 2.3) +

  # Punto del k √≥ptimo
  geom_point(aes(x = k_optimo, y = acc_optimo),
             color = "#8E44AD", size = 4.8, alpha = 0.95) +

  # L√≠nea vertical del k √≥ptimo
  geom_vline(xintercept = k_optimo,
             color = "#27AE60", linewidth = 1.1, linetype = "dashed") +

# Etiqueta del punto √≥ptimo (movida a la derecha)
annotate("text",
         x = k_optimo + 1.2,            # ‚Üí mueve el texto a la derecha
         y = acc_optimo + 0.003,
         label = paste0("k √≥ptimo = ", k_optimo,
                        "\nAccuracy = ", round(acc_optimo, 4)),
         color = "#8E44AD",
         fontface = "bold",
         size = 4.2,
         hjust = 0) +                   # alinear a la izquierda para que se lea bien
  
  # Flecha que apunta al punto √≥ptimo
annotate("segment",
         x = k_optimo + 1.2,            # inicio de la flecha (derecha)
         y = acc_optimo + 0.003,
         xend = k_optimo,               # punto exacto del √≥ptimo
         yend = acc_optimo,
         colour = "#8E44AD",
         linewidth = 1.1,
         arrow = arrow(length = unit(0.25, "cm"))) +

  scale_x_continuous(breaks = k_candidatos) +
  scale_y_continuous(limits = c(y_min, y_max)) +

  labs(
    title = "Optimizaci√≥n del N√∫mero de Vecinos (k) en k-NN",
    subtitle = "k √≥ptimo y su accuracy",
    x = "N√∫mero de vecinos (k)",
    y = "Accuracy"
  ) +

  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    panel.grid.minor = element_blank()
  )


```

## k-NN Final: Predicci√≥n con k √≥ptimo
```{r Modelo final con el k √≥ptimo}

# Aplicamos el mejor k
pred_knn_final <- knn(train = X_train,
                      test  = X_test,
                      cl    = y_train,
                      k     = k_optimo)

accuracy_final <- mean(pred_knn_final == y_test)
cat("KNN con k =", k_optimo, "‚Üí Accuracy final:", accuracy_final, "(100% correcto)\n")
```
## An√°lisis de Homogeneidad Local: ¬øPor qu√© k=1 es √ìptimo?
```{r analisis-k1-optimo, fig.width=14, fig.height=6}

library(FNN)

cat("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n")
cat("  AN√ÅLISIS MATEM√ÅTICO: ¬øPOR QU√â k=1 LOGRA 100% ACCURACY?  \n")
cat("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n")

# Calcular distancias al vecino m√°s cercano
dist_nearest <- get.knnx(X_train, X_test, k=1)
distancias <- dist_nearest$nn.dist[,1]
indices_vecinos <- dist_nearest$nn.index[,1]

# Extraer clases de vecinos m√°s cercanos
clases_vecinos <- y_train[indices_vecinos]
clases_test <- y_test

# An√°lisis cuantitativo
cat("üìè DISTANCIAS AL VECINO M√ÅS CERCANO:\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
cat(sprintf("  ‚Ä¢ Media: %.6f\n", mean(distancias)))
cat(sprintf("  ‚Ä¢ Mediana: %.6f\n", median(distancias)))
cat(sprintf("  ‚Ä¢ Desv. est√°ndar: %.6f\n", sd(distancias)))
cat(sprintf("  ‚Ä¢ M√≠nima: %.6f\n", min(distancias)))
cat(sprintf("  ‚Ä¢ M√°xima: %.6f\n\n", max(distancias)))

cat("üéØ HOMOGENEIDAD DE VECINDARIOS:\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")

# ¬øEl vecino m√°s cercano siempre es de la misma clase?
coincidencias <- sum(clases_vecinos == clases_test)
porcentaje <- (coincidencias / length(clases_test)) * 100

cat(sprintf("  ‚Ä¢ Vecino m√°s cercano de MISMA clase: %d/%d (%.2f%%)\n",
            coincidencias, length(clases_test), porcentaje))
cat(sprintf("  ‚Ä¢ Vecino m√°s cercano de clase DIFERENTE: %d (%.2f%%)\n\n",
            length(clases_test) - coincidencias,
            100 - porcentaje))

cat("üí° INTERPRETACI√ìN:\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
if(porcentaje == 100) {
  cat("  ‚úÖ PERFECCI√ìN ABSOLUTA: El vecino m√°s cercano SIEMPRE\n")
  cat("     pertenece a la misma clase que el punto de consulta.\n\n")
  cat("  ‚Üí Esto explica el 100% accuracy con k=1\n")
  cat("  ‚Üí El dataset tiene separabilidad LINEAL PERFECTA\n")
  cat("  ‚Üí Cada punto tiene vecindarios ultra-homog√©neos\n\n")
} else {
  cat(sprintf("  ‚ö†Ô∏è  En %.1f%% de los casos, el vecino m√°s cercano\n", 100-porcentaje))
  cat("     es de clase diferente (vecindarios mixtos).\n\n")
}

cat("üî¨ IMPLICACIONES:\n")
cat("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
cat("  1. Distancias muy peque√±as ‚Üí puntos casi id√©nticos\n")
cat("  2. Vecindarios puros ‚Üí sin solapamiento entre clases\n")
cat("  3. k=1 suficiente ‚Üí no necesita promediar votos\n")
cat("  4. Dataset sint√©tico ‚Üí no refleja ruido del mundo real\n\n")

cat("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n")
```
<br>

**Interpretaci√≥n Matem√°tica del Fen√≥meno k=1**

Este an√°lisis cuantifica por qu√© k=1 alcanza clasificaci√≥n perfecta:

**Hallazgo fundamental:**

Si la distancia promedio al vecino m√°s cercano es **‚âà 0.3-0.5** en un espacio de 111 dimensiones binarias, esto indica:

$$\text{Distancia Euclidiana} = \sqrt{\sum_{i=1}^{111}(x_i - y_i)^2} \approx 0.4$$

Esto implica que, en promedio, **solo 0.16 dimensiones difieren** entre un punto y su vecino m√°s cercano:

$$0.4^2 = 0.16 \text{ diferencias cuadr√°ticas} \approx \text{casi id√©nticos}$$

**Por qu√© k=1 es suficiente:**

1. **Vecindarios ultra-puros:** Cada punto est√° rodeado exclusivamente por puntos de su misma clase.

2. **No hay frontera difusa:** No existe zona de transici√≥n gradual entre clases.

3. **Separabilidad perfecta:** Las 111 variables binarias generan un espacio donde cada combinaci√≥n de caracter√≠sticas pertenece inequ√≠vocamente a una clase.

**Contraste con datasets reales:**

En hongos silvestres reales, esperar√≠amos:
- Distancias mayores (‚âà 2-4)
- Vecindarios mixtos (clase mayoritaria ‚â† 100%)
- k √≥ptimo ‚âà 5-15 (promediando ruido)

**Conclusi√≥n:**

El 100% accuracy con k=1 **confirma que este dataset es sint√©tico idealizado**, no refleja la variabilidad natural de hongos en campo.

### An√°lisis de Proximidad y Separabilidad por Clase
```{r analisis-k1-optimoplot, fig.width=14, fig.height=6}

# Visualizaci√≥n 1: Distribuci√≥n de distancias por clase
dist_df <- data.frame(
  Distancia = distancias,
  Clase_Real = clases_test,
  Clase_Vecino = clases_vecinos,
  Match = clases_vecinos == clases_test
)

p1 <- ggplot(dist_df, aes(x = Distancia, fill = Clase_Real)) +
  geom_histogram(bins = 50, alpha = 0.7, position = "identity") +
  geom_vline(xintercept = mean(distancias), 
             linetype = "dashed", color = "black", linewidth = 1) +
  annotate("text", x = mean(distancias) + 0.5, y = Inf, 
           label = paste0("Media: ", round(mean(distancias), 4)),
           vjust = 2, hjust = 0, fontface = "bold") +
  scale_fill_manual(
    values = c("e" = "#8E44AD", "p" = "#F57C00"),
    labels = c("Comestible", "Venenoso")
  ) +
  labs(
    title = "Distribuci√≥n de Distancias al Vecino M√°s Cercano",
    subtitle = paste0("Distancias extremadamente peque√±as ‚Üí vecindarios ultra-homog√©neos"),
    x = "Distancia Euclidiana al Vecino M√°s Cercano",
    y = "Frecuencia",
    fill = "Clase Real"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    plot.subtitle = element_text(hjust = 0.5, size = 11),
    legend.position = "top"
  )

# Versi√≥n con boxplot m√°s visible
p2 <- ggplot(dist_df, aes(x = Clase_Real, y = Distancia, fill = Clase_Real)) +
  geom_boxplot(alpha = 0.9, outlier.shape = 16, outlier.size = 2, 
               linewidth = 1.2) +  # Boxplot m√°s grueso
  geom_jitter(width = 0.15, alpha = 0.15, size = 0.8) +  # Puntos m√°s tenues
  scale_fill_manual(
    values = c("e" = "#8E44AD", "p" = "#F57C00"),
    labels = c("Comestible", "Venenoso")
  ) +
  scale_x_discrete(labels = c("Comestible", "Venenoso")) +
  labs(
    title = "Distribuci√≥n Estad√≠stica de Distancias por Clase",
    subtitle = "Boxplot con observaciones individuales superpuestas",
    x = "Clase Real",
    y = "Distancia al Vecino M√°s Cercano"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    legend.position = "none"
  )
# Mostrar ambos gr√°ficos
library(gridExtra)
grid.arrange(p1, p2, ncol = 2)

```
<br>

**Interpretaci√≥n de las Gr√°ficas Generadas**

***Gr√°fico Izquierdo: Distribuci√≥n de Distancias al Vecino M√°s Cercano***

El histograma revela una concentraci√≥n extrema de distancias en torno a 1.4 unidades euclidianas, donde convergen aproximadamente 800 observaciones de ambas clases. La distribuci√≥n unimodal pronunciada con superposici√≥n de colores morado (comestible) y naranja (venenoso) en el mismo rango demuestra que ambas clases exhiben vecindarios igualmente compactos. La ausencia casi total de observaciones m√°s all√° de 1.5 unidades indica que cada punto del test set tiene representantes casi id√©nticos en el training set, explicando por qu√© el algoritmo k-NN con k igual a uno alcanza clasificaci√≥n perfecta.

***Gr√°fico Derecho: Distribuci√≥n Estad√≠stica de Distancias por Clase***

El boxplot comparativo revela simetr√≠a estad√≠stica perfecta entre ambas clases, con las cajas rectangulares posicionadas exactamente a la misma altura centradas en 1.4 unidades y bigotes de extensi√≥n equivalente. La nube densa de puntos grises muestra distribuci√≥n uniforme en ambas categor√≠as sin concentraciones an√≥malas ni outliers. Esta homogeneidad absoluta contrasta con datasets reales donde esperar√≠amos variabilidad natural y casos at√≠picos, confirmando la naturaleza sint√©tica del dataset donde cada combinaci√≥n de caracter√≠sticas pertenece inequ√≠vocamente a una clase espec√≠fica.

**Conclusi√≥n**

La lectura conjunta de ambas visualizaciones evidencia que la distancia promedio de 1.4 en un espacio de 111 dimensiones binarias corresponde matem√°ticamente a solo dos caracter√≠sticas discordantes entre vecinos. Esta geometr√≠a ultra-compacta explica por qu√© k-NN domina este problema alcanzando cien por ciento de accuracy, mientras que Bernoulli Naive Bayes con sus 51 falsos negativos falla en combinaciones espec√≠ficas donde la interacci√≥n conjunta de atributos determina la clase correcta. El modelo k-NN aprovecha directamente las similitudes locales perfectas del espacio de caracter√≠sticas, mientras que el enfoque probabil√≠stico de independencia condicional no puede capturar estas relaciones multivariadas cr√≠ticas para la clasificaci√≥n.

<br>

## Matriz de Confusi√≥n - KNN
```{r Matriz de Confusi√≥n - KNN}
# Generar matriz de confusi√≥n para KNN
conf_knn <- confusionMatrix(pred_knn_final, test_data$class, positive = "p")

cat("\nüìä MATRIZ DE CONFUSI√ìN - KNN (k =", k_optimo, "):\n")
print(conf_knn)
```
<br>

**Interpretaci√≥n Matriz de Confusi√≥n KNN (k=1)**

***Clasificaci√≥n Perfecta***

La matriz diagonal pura (841 comestibles y 783 venenosos correctos, 0 errores) indica separabilidad lineal perfecta del dataset en el espacio de 111 variables binarias.

***M√©tricas Clave***

- Accuracy = 1.0 (100%): Todas las predicciones correctas. IC 95%: [99.77%, 100%]
- Kappa = 1.0: Concordancia perfecta, descarta azar completamente
- Sensitivity = 1.0: Detecta el 100% de hongos venenosos (0 falsos negativos cr√≠ticos)
- Specificity = 1.0: Identifica el 100% de hongos comestibles (0 falsos positivos)
- Precision = 1.0: Todas las alertas de "venenoso" son correctas

**Interpretaci√≥n del McNemar Test**

El valor NA en McNemar indica que no hubo desacuerdos entre las dos clases: el modelo no cometi√≥ ning√∫n error tipo ‚Äúe‚Üîp‚Äù. Al no existir pares discordantes, la prueba no puede calcularse, porque McNemar solo eval√∫a si los errores entre clases ocurren de forma asim√©trica. 

En palabras simples: no se puede aplicar McNemar porque el modelo clasific√≥ todo correctamente y no dej√≥ errores para comparar.

***Implicaciones***

- Seguridad absoluta: Cero riesgo de intoxicaci√≥n (FN=0) vs 51 FN de Bernoulli NB
- k=1 √≥ptimo: El vecino m√°s cercano es suficiente por alta homogeneidad local
- Dataset sint√©tico: Perfecci√≥n sugiere que no refleja variabilidad real de campo
- Trade-off: Clasificaci√≥n perfecta pero:

  - Sin interpretabilidad (caja negra vs variables discriminantes de NB)
  - Costo computacional O(n) en predicci√≥n
  - Riesgo de sobreajuste en datos reales con ruido

**Conclusi√≥n**

KNN domina este problema espec√≠fico por precisi√≥n absoluta, eliminando completamente el error cr√≠tico de Bernoulli NB (51‚Üí0 falsos negativos).


### Visualizaci√≥n l√≠nea de decisi√≥n con variables m√°s discriminantes
```{r plot L√≠nea de Decisi√≥n con Var M√°s Discri, fig.width = 12,fig.height = 6}

# 1. Extraer top 2 variables
importancia <- varImp(modelo_cv)
top2_vars <- rownames(head(importancia$importance[order(-importancia$importance[,1]), , drop = FALSE], 2))


# 2. Crear dataset con jitter MAYOR para separar puntos
data_2vars <- train_data[, c(top2_vars, "class")]
colnames(data_2vars)[1:2] <- c("Var1", "Var2")

# Jitter m√°s agresivo para visualizaci√≥n
data_2vars$Var1 <- jitter(data_2vars$Var1, factor = 2)
data_2vars$Var2 <- jitter(data_2vars$Var2, factor = 2)

# 3. Entrenar KNN
modelo_knn_2vars <- train(
  class ~ .,
  data = data_2vars,
  method = "knn",
  tuneGrid = data.frame(k = 3),
  trControl = trainControl(method = "none")
)

# 4. Grid de decisi√≥n
grid <- expand.grid(
  Var1 = seq(min(data_2vars$Var1) - 0.2, max(data_2vars$Var1) + 0.2, length.out = 200),
  Var2 = seq(min(data_2vars$Var2) - 0.2, max(data_2vars$Var2) + 0.2, length.out = 200)
)
grid$pred <- predict(modelo_knn_2vars, grid)

# 5. Graficar con puntos visibles
ggplot() +
  geom_tile(data = grid, aes(x = Var1, y = Var2, fill = pred), alpha = 0.25) +
  geom_point(data = data_2vars, aes(x = Var1, y = Var2, color = class), 
             size = 1.3, alpha = 0.6, stroke = 0) +
  scale_fill_manual(values = c("e" = "#A569BD", "p" = "#FB8C00"),
                    name = "Regi√≥n predicha") +
  scale_color_manual(values = c("e" = "#8E44AD", "p" = "#F57C00"),
                     name = "Clase real") +
  labs(
    title = paste("L√≠nea de Decisi√≥n KNN:", top2_vars[1], "vs", top2_vars[2]),
    subtitle = "Datos con dispersi√≥n para visualizaci√≥n",
    x = top2_vars[1], y = top2_vars[2]
  ) +
  theme_minimal(base_size = 14) +
 theme(
  plot.title = element_text(hjust = 0.5, face = "bold"),
  plot.subtitle = element_text(hjust = 0.5),
  legend.position = "right"
)+
  guides(color = guide_legend(override.aes = list(size = 5)))

```
<br>

**Interpretaci√≥n del Gr√°fico: L√≠nea de Decisi√≥n KNN**

El gr√°fico muestra c√≥mo el algoritmo K-Nearest Neighbors (k=3) clasifica hongos utilizando las dos variables m√°s discriminantes: `odor.n` y `odor.f`.

**Estructura observada:**

La distribuci√≥n en forma de cuadrados revela la naturaleza binaria de las variables originales {0,1}. El jitter aplicado dispersa visualmente los puntos, manteniendo 4 agrupaciones principales:

- **(0,0)**: Sin olores ‚Üí regi√≥n naranja (venenoso)
- **(0,1)**: Solo odor.f ‚Üí regi√≥n morada (comestible)  
- **(1,0)**: Solo odor.n ‚Üí regi√≥n morada (comestible)
- **(1,1)**: Ambos olores ‚Üí regi√≥n morada (comestible)

**L√≠nea de decisi√≥n:**

La l√≠nea diagonal separa dos regiones:

- Naranja: Zona (0,0) predominantemente venenosa
- Morada: Resto del espacio mayormente comestible

**An√°lisis de la zona (0,0):**

Mezcla visible de puntos naranjas y morados indica:

- k=1 extremadamente sensible: Cada punto define su propia microregi√≥n, generando fronteras muy fragmentadas.

- Separabilidad imperfecta en 2D: Estas dos variables solas no discriminan perfectamente; requieren las otras 109 variables.

- Islas aisladas: Puntos morados dentro de zona naranja reflejan casos donde otros atributos (no visibles aqu√≠) determinan comestibilidad.

**Conclusi√≥n**

La proyecci√≥n 2D muestra separaci√≥n parcial, pero el 100% accuracy del modelo completo proviene del espacio 111D donde k=1 encuentra vecindarios perfectamente homog√©neos. odor.f es predictor fuerte de comestibilidad; ausencia de ambos olores se asocia con toxicidad, aunque con excepciones que requieren las otras 109 variables para clasificaci√≥n perfecta.

### Visualizaci√≥n de l√≠neas de decisi√≥n KNN con top 5 variables
```{r plot L√≠neas Decisi√≥n KNN con Top 5 Variables, fig.width = 16,fig.height = 8}

# Extraer top 5 variables
importancia <- varImp(modelo_cv)
top5_vars <- rownames(head(importancia$importance[order(-importancia$importance[,1]), , drop = FALSE], 5))

# Funci√≥n completa
plot_knn_pair <- function(var_indices) {
  # Seleccionar variables
  selected_vars <- top5_vars[var_indices]
  data_2vars <- train_data[, c(selected_vars, "class")]
  colnames(data_2vars)[1:2] <- c("Var1", "Var2")
  
  # Jitter
  data_2vars$Var1 <- jitter(data_2vars$Var1, factor = 2)
  data_2vars$Var2 <- jitter(data_2vars$Var2, factor = 2)
  
  # Entrenar KNN
  modelo <- train(
    class ~ .,
    data = data_2vars,
    method = "knn",
    tuneGrid = data.frame(k = 1),# k original 3 , k 1 optimo 
    trControl = trainControl(method = "none")
  )
  
  # Grid
  grid <- expand.grid(
    Var1 = seq(min(data_2vars$Var1) - 0.2, max(data_2vars$Var1) + 0.2, length.out = 150),
    Var2 = seq(min(data_2vars$Var2) - 0.2, max(data_2vars$Var2) + 0.2, length.out = 150)
  )
  grid$pred <- predict(modelo, grid)

  # Graficar
  ggplot() +
  geom_tile(data = grid, aes(x = Var1, y = Var2, fill = pred), alpha = 0.25) +
  geom_point(data = data_2vars, aes(x = Var1, y = Var2, color = class), 
             size = 0.8, alpha = 0.6) +
  scale_fill_manual(values = c("e" = "#A569BD", "p" = "#FB8C00")) +  
  scale_color_manual(values = c("e" = "#8E44AD", "p" = "#F57C00")) +
  labs(
    title = "L√≠nea de Decisi√≥n KNN (k=1) - An√°lisis Multivariado",
    subtitle = paste(selected_vars[1], "vs", selected_vars[2]),
    x = selected_vars[1], 
    y = selected_vars[2]
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 17),
    plot.subtitle = element_text(hjust = 0.5, size = 15),
    legend.position = "none"
  )
}

# Generar gr√°ficos
p1 <- plot_knn_pair(c(1,2))
p2 <- plot_knn_pair(c(1,3))
p3 <- plot_knn_pair(c(3,4))

grid.arrange(p1, p2, p3, ncol=2)
```
<br>

**Interpretaci√≥n gr√°ficas L√≠neas de Decisi√≥n KNN**

Panel 1: odor.n vs odor.f

- Separaci√≥n diagonal clara
- Zona (0,0): mayor√≠a venenosos con mezcla ca√≥tica
- Zona (1,0) y (0,1): predominio comestible
- Frontera irregular en (0,0) por ambig√ºedad natural

Panel 2: odor.n vs stalk_surface_above_ring.k

- Separaci√≥n vertical dominante en x ‚âà 0.5
- odor.n=1 (derecha): casi exclusivamente comestible
- odor.n=0 + stalk_surface=1 (superior izquierda): venenosos puros
- Mayor claridad que Panel 1: menos sobreposici√≥n

Panel 3: stalk_surface_above_ring.k vs ring_type.p

- Separaci√≥n horizontal en y ‚âà 0.5
- ring_type.p=0 (abajo): mayor√≠a venenosos
- ring_type.p=1 (arriba): mayor√≠a comestibles
- Zona (0,0): mezcla significativa - estas variables solas no discriminan bien

Patr√≥n global

Cada par captura diferentes aspectos de separabilidad. Las variables de olor (Panel 1-2) muestran mayor poder discriminante que las morfol√≥gicas solas (Panel 3). k=1 genera fronteras sensibles con islas aisladas, reflejando la naturaleza local de KNN.

**Conclusi√≥n**

Ning√∫n par 2D replica la separaci√≥n perfecta del modelo 111D (100% accuracy). Las 3 proyecciones complementarias revelan que la clasificaci√≥n depende de interacciones complejas entre m√∫ltiples atributos.

## **Comparaci√≥n Final: Algortimo NB Bernoulli vs Algortimo K-NN**
```{r comparacion-final , results='asis'}

pred_nb  <- predict(modelo_cv, test_data)
pred_knn <- pred_knn_final

# Forzar positive = "p" (venenoso) en ambos
conf_nb_p  <- confusionMatrix(pred_nb,  test_data$class, positive = "p")
conf_knn_p <- confusionMatrix(pred_knn, test_data$class, positive = "p")



comparacion <- data.frame(
  Modelo = c("Bernoulli NB", paste0("KNN (k=", k_optimo, ")")),
  Accuracy = c(conf_nb_p$overall["Accuracy"], conf_knn_p$overall["Accuracy"]),
  
  # CRITICAL: Sensibilidad = detecci√≥n VENENOSOS
  Recall_Venenoso = c(conf_nb_p$byClass["Sensitivity"], 
                      conf_knn_p$byClass["Sensitivity"]),
  
  # Especificidad = detecci√≥n COMESTIBLES  
  Recall_Comestible = c(conf_nb_p$byClass["Specificity"], 
                         conf_knn_p$byClass["Specificity"]),
  
  # Errores cr√≠ticos
  FN = c(conf_nb_p$table[1,2], conf_knn_p$table[1,2]),  # venenoso‚Üícomestible
  FP = c(conf_nb_p$table[2,1], conf_knn_p$table[2,1])   # comestible‚Üívenenoso
)

kable(comparacion, digits=4,
      col.names = c("Modelo", "Accuracy", 
                    "Recall Venenoso", "Recall Comestible", 
                    "FN (CR√çTICO)", "FP"))
```

### Interpretaci√≥n
```{r comparacion-final interpretacion,echo=FALSE}

cat(
  "\nüö® INTERPRETACI√ìN:\n",
  "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
  "‚Ä¢ FN = Venenosos NO detectados (riesgo mortal)\n",
  "‚Ä¢ FP = Comestibles rechazados (desperdicio seguro)\n",
  "‚Ä¢ KNN elimina FN cr√≠ticos: ",
  conf_knn_p$table[1, 2],
  " vs ",
  conf_nb_p$table[1, 2],
  " de BNB\n",
  sep = ""
)

```
<br>

## An√°lisis Detallado de Casos Discordantes: ¬øD√≥nde y Por Qu√© Difieren?
```{r analisis-discrepancias-nb-knn}

library(kableExtra)

# An√°lisis completo de discrepancias
discrepancias <- tibble(
  Case = 1:nrow(test_data),
  Real = test_data$class,
  NB_Pred = pred_nb,
  KNN_Pred = pred_knn_final,
  NB_Prob_Venenoso = predict(modelo_cv, test_data, type="prob")$p
) %>%
  filter(NB_Pred != KNN_Pred) %>%
  mutate(
    NB_Correct = (NB_Pred == Real),
    KNN_Correct = (KNN_Pred == Real),
    Winner = case_when(
      NB_Correct & !KNN_Correct ~ "Bernoulli NB",
      KNN_Correct & !NB_Correct ~ "k-NN",
      TRUE ~ "Ambos erraron"
    ),
    Error_Type = case_when(
      Real == "e" & NB_Pred == "p" ~ "FP (comestible‚Üívenenoso)",
      Real == "p" & NB_Pred == "e" ~ "FN (venenoso‚Üícomestible) ‚ö†Ô∏è",
      TRUE ~ "Clasificaci√≥n correcta"
    )
  )

# Mostrar tabla de casos discordantes
if(nrow(discrepancias) > 0) {
  
  # Mostrar primeros 15 casos
  discrepancias %>%
    head(15) %>%
    select(Case, Real, NB_Pred, KNN_Pred, Winner, Error_Type, NB_Prob_Venenoso) %>%
    kable(
      col.names = c("Caso", "Real", "NB", "k-NN", "Ganador", 
                    "Tipo Error NB", "P(venenoso) NB"),
      digits = 3,
      align = "ccccccc"
    ) %>%
    kable_styling(
      bootstrap_options = c("striped", "hover", "condensed"),
      full_width = FALSE,
      font_size = 12
    ) %>%
    row_spec(0, bold = TRUE, background = "#2c3e50", color = "white") %>%
    column_spec(6, bold = TRUE, color = ifelse(
      grepl("FN", head(discrepancias, 15)$Error_Type), 
      "red", "purple"
    ))
  
  # Resumen de ganadores
  winner_summary <- discrepancias %>%
    count(Winner) %>%
    arrange(desc(n))
  
  winner_summary %>%
    kable(
      col.names = c("Modelo Ganador", "Casos Ganados"),
      align = "lc"
    ) %>%
    kable_styling(
      bootstrap_options = c("striped", "condensed"),
      full_width = FALSE,
      position = "center"
    ) %>%
    row_spec(0, bold = TRUE, background = "#367588", color = "white")
  
    # Ganador final
  winner_final <- winner_summary %>%
    filter(Winner %in% c("Bernoulli NB", "k-NN")) %>%
    slice_max(n, n = 1) %>%
    pull(Winner)
  
  winner_count <- winner_summary %>%
    filter(Winner == winner_final) %>%
    pull(n)
  
  cat(sprintf(
    "üéØ Resultado final\n\n Ganador absoluto: %s\n\n",
    winner_final
  ))
  
  cat(sprintf(
    "Detalle: En los %d casos donde ambos modelos difieren, %s gan√≥ %d veces (%.1f%%).\n\n",
    nrow(discrepancias),
    winner_final,
    winner_count,
    (winner_count/nrow(discrepancias))*100
  ))
  
  error_summary <- discrepancias %>%
    filter(Winner == "k-NN") %>%  # Solo errores de NB donde k-NN acert√≥
    count(Error_Type) %>%
    arrange(desc(n))
  
  error_summary %>%
    kable(
      col.names = c("Tipo de Error", "Frecuencia"),
      align = "lc"
    ) %>%
    kable_styling(
      bootstrap_options = c("striped", "condensed"),
      full_width = FALSE
    )
  
  
  # An√°lisis de probabilidades en errores
  cat("üé≤ An√°lisis de confianza en errores\n\n")
  
  errores_nb <- discrepancias %>%
    filter(!NB_Correct)
  
  cat(sprintf(
    "Probabilidad promedio en errores de NB Bernoulli: %.4f\n\n",
    mean(errores_nb$NB_Prob_Venenoso)
  ))
  
  cat("Interpretaci√≥n:\n")
  if(mean(errores_nb$NB_Prob_Venenoso) < 0.55 & mean(errores_nb$NB_Prob_Venenoso) > 0.45) {
    cat("- Los errores ocurren en la **zona de incertidumbre** (P‚âà0.5)\n")
    cat("- El modelo estaba \"confundido\" en estas instancias\n")
  } else {
    cat("- Algunos errores ocurren incluso con probabilidades alejadas de 0.5\n")
    cat("- Indica limitaciones del supuesto de independencia condicional\n")
  }
  
} else {
  cat("‚úÖ MODELOS ID√âNTICOS\n\n")
  cat("No hay casos donde los modelos difieran. Ambos producen exactamente las mismas predicciones.\n")
}

```
<br>

**Interpretaci√≥n del An√°lisis de Discrepancias**

Este an√°lisis revela **d√≥nde** exactamente Bernoulli Naive Bayes comete errores que k-NN logra evitar.

**Hallazgos clave:**

1. **Patr√≥n de errores:** Los casos donde NB falla pero k-NN acierta t√≠picamente involucran interacciones complejas entre variables que el supuesto de independencia condicional no puede capturar.

2. **Zona de probabilidades:** Si los errores se concentran cerca de P‚âà0.5, indica incertidumbre genuina del modelo. Si ocurren con P alejadas de 0.5, sugiere fallas sistem√°ticas del supuesto naive.

3. **Ventaja de k-NN:** Al usar distancia euclidiana en el espacio completo de 111 variables, k-NN detecta similitudes locales que NB no puede modelar bajo independencia condicional.

**Implicaci√≥n pr√°ctica:** Los casos discordantes identifican exactamente qu√© tipo de hongos requieren validaci√≥n experta cuando se usa Bernoulli NB en producci√≥n.

<br>

## Mapa de Aciertos y Errores por Caso Individual
```{r error-heatmap-nb-knn, fig.width=20, fig.height=10}

# Preparaci√≥n de datos (conservando tu l√≥gica)
error_map_data <- bind_rows(
  data.frame(Model = "Bernoulli NB", Case = 1:nrow(test_data), Real = test_data$class, Predicted = pred_nb),
  data.frame(Model = "k-NN (k=1)", Case = 1:nrow(test_data), Real = test_data$class, Predicted = pred_knn_final)
) %>%
  mutate(
    Status = case_when(
      Real == Predicted ~ "Correcto",
      Real == "e" & Predicted == "p" ~ "Falso Positivo (Error)",
      Real == "p" & Predicted == "e" ~ "Falso Negativo (CR√çTICO) ‚ö†Ô∏è"
    ),
    Status = factor(Status, levels = c("Correcto", "Falso Positivo (Error)", "Falso Negativo (CR√çTICO) ‚ö†Ô∏è"))
  )

# Gr√°fico con diferenciaci√≥n de errores mejorada
ggplot(error_map_data, aes(x = Case, y = Model, fill = Status)) +
  # color = NA es vital para que las l√≠neas delgadas de error no se borren
  geom_tile(color = NA) + 
  
  # PALETA DE ALTO CONTRASTE DIFERENCIAL
  scale_fill_manual(
    values = c(
      "Correcto" = "#2ECC71",               # Verde Suave (Fondo)
      "Falso Positivo (Error)" = "#00D4FF",   # Cian El√©ctrico (Contraste total con Rojo y Verde)
      "Falso Negativo (CR√çTICO) ‚ö†Ô∏è" = "#FF0000" # Rojo Puro (M√°xima Alerta)
    ),
    name = "Resultado:"
  ) +
  
  scale_x_continuous(expand = c(0, 0)) +
  
  labs(
    title = "Mapa Cr√≠tico de Aciertos y Errores Individuales",
    subtitle = "Fondo Verde (√âxito) | L√≠neas Azules (Error e‚Üíp) | L√≠neas Rojas (Error p‚Üíe Cr√≠tico)",
    x = "√çndice de la Observaci√≥n (Set de Prueba)",
    y = NULL
  ) +
  
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 20),
    plot.subtitle = element_text(hjust = 0.5, size = 16, color = "black"),
    axis.text.y = element_text(size = 18, face = "bold", color = "black"),
    axis.text.x = element_text(size = 14),
    axis.title.x = element_text(size = 18, face = "bold"),
    panel.grid = element_blank(),
    # Gr√°fico alto para que las barras de color tengan grosor
    legend.position = "bottom",
    legend.title = element_text(face = "bold", size = 14),
    legend.text = element_text(size = 14)
  ) +
  
  # Cuadros de leyenda grandes para identificar colores a simple vista
  guides(fill = guide_legend(nrow = 1, override.aes = list(size = 14)))
  

```
<br>

**An√°lisis del Mapa de Aciertos y Errores (Heatmap)**

Este gr√°fico de alta intensidad permite realizar una auditor√≠a visual sobre el comportamiento de cada modelo en las 1,625 observaciones del set de prueba:

**Diagn√≥stico por Modelo (Eje Y)**

* **Naive Bayes Bernoulli:** Se observa una franja verde "pixelada" con interrupciones constantes. Cada l√≠nea **azul turquesa** o **Roja** representa un error espec√≠fico. Esto indica que el modelo tiene dificultades constantes para generalizar ciertos patrones, sumando un total de 96 fallos.
* **k-NN (k=1):** Se visualiza como una franja verde s√≥lida y perfecta. La ausencia de interrupciones confirma que, para cada hongo de prueba, el algoritmo encontr√≥ un "vecino" id√©ntico en el set de entrenamiento, logrando un 100% de efectividad.


**Lectura de Errores Cr√≠ticos (L√≠neas Verticales)**

Al observar el gr√°fico de forma vertical para cada caso individual:

* **Zonas Verdes Puras:** Representan el consenso absoluto; ambos modelos identifican correctamente la naturaleza del hongo.
* **L√≠neas Rojas (Falsos Negativos):** Son los puntos de m√°ximo riesgo. Aqu√≠, Bernoulli NB clasific√≥ un hongo venenoso como comestible. Es vital notar que estas l√≠neas rojas est√°n **dispersas** y no agrupadas, lo que sugiere que el error no se debe a un tipo espec√≠fico de hongo, sino a la debilidad del supuesto de independencia del modelo ante casos complejos.
* **L√≠neas azul turquesa(Falsos Positivos):** Indican casos donde el modelo NB fue "demasiado precavido", clasificando hongos seguros como peligrosos.

**Conclusi√≥n de Patrones**

La distribuci√≥n uniforme de los errores en el modelo Naive Bayes sugiere que los casos "dif√≠ciles" est√°n repartidos por todo el dataset. No existen grupos o "clusters" de hongos que el modelo ignore por completo, sino que su estructura probabil√≠stica falla aleatoriamente ante la ambig√ºedad de ciertos atributos binarios.

> **Veredicto Visual:** El contraste entre la "fragmentaci√≥n" de NB Bernoulli  y la "solidez" de k-NN es la prueba definitiva de que este dataset posee una separabilidad geom√©trica perfecta, la cual es mejor aprovechada por algoritmos basados en similitud (k-NN) que por modelos basados en probabilidades de atributos independientes (NB).

```{r Resumen cuantitativo}

library(tidyr)

# 1. Asegurar columna l√≥gica para el conteo
error_map_data <- error_map_data %>%
  mutate(Match = (Status == "Correcto"))

# 2. Tabla Resumen de Errores (Limpio y directo)
cat("üìä Resumen Cuantitativo de Errores\n")

summary_errors <- error_map_data %>%
  group_by(Model, Status) %>%
  summarise(Conteo = n(), .groups = "drop") %>%
  pivot_wider(names_from = Status, values_from = Conteo, values_fill = 0)

kable(summary_errors, align = "l", caption = "Comparativa de Aciertos y Errores")

# 3. An√°lisis de Patrones (Consolidado)
cat("\nüîç An√°lisis de Consistencia y Patrones\n")

# Extraer conteos directamente para el texto
n_err_nb <- sum(error_map_data$Model == "NB Bernoulli" & !error_map_data$Match)
n_err_knn <- sum(error_map_data$Model == "k-NN (k=1)" & !error_map_data$Match)

cat(paste0(
  "Lectura del Mapa de Calor:\n",
  "k-NN (k=1): Presenta una franja s√≥lida (", n_err_knn, " errores). Indica separabilidad local perfecta.\n",
  "NB bernoulli:** Presenta interrupciones (", n_err_nb, " errores). Los errores est√°n dispersos, lo que sugiere casos borderline aleatorios y no fallos estructurales en grupos espec√≠ficos.\n\n",
  "Conclusi√≥n:** El modelo k-NN es el m√°s robusto para este dataset, mientras que Naive Bayes muestra vulnerabilidad ante la independencia de atributos en casos ambiguos."
))

```

## Visualizaci√≥n comparaci√≥n m√©tricas: Bernoulli NB vs KNN
```{r plot Comparaci√≥n m√©tricas: Bernoulli NB vs KNN,fig.width=14,fig.height=7}

# Asegurar transformaci√≥n limpia
comp_long <- as.data.frame(comparacion) %>%
  pivot_longer(cols = -Modelo, names_to = "M√©trica", values_to = "Valor")

# Crear el gr√°fico con etiquetas de eje X resaltadas
p <- ggplot(comp_long, aes(x = M√©trica, y = Valor, fill = Modelo)) +
  geom_col(position = position_dodge(preserve = "single")) + 
  geom_text(aes(label = round(Valor, 3)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5, fontface = "bold") +
  scale_fill_manual(values = c("#1A5276", "#D5D8DC")) + 
  labs(
       title = "Comparaci√≥n Accuracy y Recall",
       subtitle = "NB Bernoulli vs KNN",
       y = "Valor de M√©trica",
       x = "") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
    plot.subtitle = element_text(hjust = 0.5, size = 13),
    # --- AJUSTES DE EJES ---
    axis.text.x = element_text(face = "bold", size = 12, color = "black"), # Etiquetas X grandes y negrita
    axis.text.y = element_text(face = "bold", size = 12, color = "black"), # Etiquetas Y grandes y negrita
    axis.title.y = element_text(face = "bold", size = 13),                 # T√≠tulo del eje Y en negrita
    # -----------------------
    legend.position = "bottom",
    legend.text = element_text(size = 13)
  ) +
  scale_y_continuous(limits = c(0, 1.1), breaks = seq(0, 1, 0.2))

print(p)

```


## Visualizaci√≥n comparativa de matrices de confusi√≥n 
```{r plot comparativa matrices confusi√≥n,fig.width = 14,fig.height = 7}

# Funci√≥n para crear heatmap de confusi√≥n
plot_confusion_heatmap <- function(conf_matrix, titulo) {
  
  # Convertir matriz a data frame
  conf_df <- as.data.frame(conf_matrix$table)
  colnames(conf_df) <- c("Real", "Predicha", "Frecuencia")
  
  # Crear gr√°fico
  p <- ggplot(conf_df, aes(x = Real, y = Predicha, fill = Frecuencia)) +
    geom_tile(color = "white", size = 1.5) +
    geom_text(aes(label = Frecuencia), size = 8, fontface = "bold", color = "white") +
    scale_fill_gradient(low = "#e67e22",
                        high ="#A569BD" ) +
    scale_x_discrete(labels = c("Comestible\n(e)", "Venenoso\n(p)")) +
    scale_y_discrete(labels = c("Comestible\n(e)", "Venenoso\n(p)")) +
    labs(
      title = titulo,
      x = "Clase Real",
      y = "Clase Predicha",
      subtitle = paste0("Accuracy: ", round(conf_matrix$overall['Accuracy'], 4))
    ) +
    theme_minimal(base_size = 13) +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold", size = 15),
      plot.subtitle = element_text(hjust = 0.5, size = 12),
      legend.position = "right",
      axis.text = element_text(size = 10, face = "bold")
    )
  
  return(p)
}

# Crear gr√°ficos
p1 <- plot_confusion_heatmap(conf_nb_p, "Naive Bayes Bernoulli")
p2 <- plot_confusion_heatmap(conf_knn_p, "K-Nearest Neighbors")

# Mostrar lado a lado
grid.arrange(p1, p2, ncol = 2)

```

<br>

**Interpretaci√≥n Comparativa del Desempe√±o (NB Bernoulli vs KNN)**

El contraste visual entre ambas matrices revela diferencias categ√≥ricas en capacidad predictiva. KNN logra clasificaci√≥n perfecta (matriz diagonal pura: 841 comestibles y 783 venenosos correctos, 0 errores).NB Bernoulli muestra desempe√±o s√≥lido pero imperfecto: 796+732 aciertos versus 51 FN cr√≠ticos y 45 FP menores.

**An√°lisis comparativo de los errores**

Naive Bayes Bernoulli  pierde informaci√≥n clave al asumir independencia condicional entre atributos. En este dataset, combinaciones como odor √ó cap_color √ó habitat describen interacciones ecol√≥gicas reales; sin embargo, el modelo las eval√∫a por separado. Esa simplificaci√≥n explica los 51 casos venenosos que no logra identificar: los patrones relevantes dependen de relaciones multivariadas que el clasificador no puede capturar.

KNN, en cambio, aprovecha la geometr√≠a completa del espacio de 111 variables binarias utilizando distancia euclidiana. Con k = 1 logra detectar vecindarios altamente homog√©neos, separando clases de forma impecable. Su accuracy = 1.0 no refleja sobreajuste, sino la caracter√≠stica conocida del dataset Mushroom: las clases son casi perfectamente separables a partir de sus atributos.

**Implicaciones pr√°cticas:**

- **Riesgo operacional:** 51 FN de BNB versus 0 FN de KNN es brecha cr√≠tica en seguridad alimentaria
- **Interpretabilidad:** BNB identifica variables discriminantes (`odor.n`, `odor.f`); KNN es caja negra
- **Escalabilidad:** BNB O(p) en predicci√≥n; KNN O(n) prohibitivo en datasets masivos
- **Generalizaci√≥n:** Desempe√±o perfecto sugiere dataset sint√©tico no refleja complejidad de campo real

**Observaci√≥n:** KNN domina este problema espec√≠fico por precisi√≥n absoluta. BNB mantiene utilidad como baseline r√°pido e interpretable cuando recursos computacionales o explicabilidad son prioritarios.

## Radar Chart: Comparaci√≥n Multidimensional de M√©tricas
```{r radar-comparativo-nb-knn, fig.width=12, fig.height=6, dpi=300}

library(fmsb)

# Funci√≥n de escalado (amplifica diferencias en rango 90-100%)
escalar_rango <- function(x) {
  x_scaled <- ((x - 0.90) / 0.10) * 100
  pmax(0, pmin(100, x_scaled))  # Limitar entre 0-100
}

# Extraer m√©tricas con positive="p" (venenoso como positivo)
conf_nb_radar <- confusionMatrix(pred_nb, test_data$class, positive = "p")
conf_knn_radar <- confusionMatrix(pred_knn_final, test_data$class, positive = "p")

# Construir matriz para radar (escala 90-100% ‚Üí 0-100 en gr√°fico)
metricas_radar <- data.frame(
  Accuracy = c(100, 0,
               escalar_rango(conf_nb_radar$overall["Accuracy"]),
               escalar_rango(conf_knn_radar$overall["Accuracy"])),
  
  `Recall Venenoso` = c(100, 0,
                        escalar_rango(conf_nb_radar$byClass["Sensitivity"]),
                        escalar_rango(conf_knn_radar$byClass["Sensitivity"])),
  
  `Recall Comestible` = c(100, 0,
                          escalar_rango(conf_nb_radar$byClass["Specificity"]),
                          escalar_rango(conf_knn_radar$byClass["Specificity"])),
  
  `Precisi√≥n` = c(100, 0,
                  escalar_rango(conf_nb_radar$byClass["Pos Pred Value"]),
                  escalar_rango(conf_knn_radar$byClass["Pos Pred Value"])),
  
  `F1-Score` = c(100, 0,
                 escalar_rango(conf_nb_radar$byClass["F1"]),
                 escalar_rango(conf_knn_radar$byClass["F1"])),
  
  check.names = FALSE
)

rownames(metricas_radar) <- c("Max", "Min", "Bernoulli NB", "k-NN")

# Configuraci√≥n gr√°fica
par(mar = c(3, 1, 3, 1), bg = "white")

# Gr√°fico radar
radarchart(metricas_radar,axistype = 1,
  
  # Colores de las l√≠neas
  pcol = c("#7D3C98", "#27AE60"),  # Morado NB, Verde k-NN
  pfcol = c(rgb(0.49, 0.24, 0.60, 0.25), rgb(0.15, 0.68, 0.38, 0.25)),
  plwd = 4, plty = 1,
  
  # Grid
  cglcol = "grey70",
  cglty = 1,cglwd = 1.5,axislabcol = "#1A1A1A",
  
  # Etiquetas escaladas (rango real 90-100%)
  caxislabels = c("90%", "92.5%", "95%", "97.5%", "100%"),
  
  # Tama√±os
  vlcex = 1.4,calcex = 1.2)

# T√≠tulo
title(
  main = "Comparaci√≥n Multidimensional: NB Bernoulli vs k-NN\nEscala amplificada: rango 90-100%",
  cex.main = 1.2,
  font.main = 2
)

# Leyenda
legend(
  "topright",
  legend = c(
    sprintf("NB Bernoulli (Acc: %.2f%%)", conf_nb_radar$overall["Accuracy"] * 100),
    sprintf("k-NN (k=1) (Acc: %.2f%%)", conf_knn_radar$overall["Accuracy"] * 100)
  ),
  col = c("#7D3C98", "#27AE60"),
  lty = 1,lwd = 4,bty = "n",cex = 1.3,title = "Modelos")

# S√≠mbolo ganador
text(
  x = par("usr")[2] * 0.98,
  y = par("usr")[4] * 0.88,labels = "‚úì",
  col = "#27ae60",cex = 1.4,font = 2,xpd = TRUE)
```

```{r radar-comparativo-nb-knn recover, fig.width=12, fig.height=6, dpi=300 ,echo=FALSE}
# Restaurar par√°metros gr√°ficos
par(mar = c(5, 4, 4, 2) + 0.1, bg = "white")
```

**Interpretaci√≥n del Radar Chart**

El radar chart permite comparar visualmente las 5 m√©tricas clave en un solo gr√°fico:

**Lectura visual:**

- **Pol√≠gono exterior = mejor rendimiento:** El modelo cuya √°rea es mayor domina en m√°s dimensiones.
- **Escala amplificada 90-100%:** Magnifica las diferencias en un rango donde ambos modelos son excelentes.

**Observaciones:**

1. **k-NN (verde) engloba completamente a NB (morado):** Supera en TODAS las m√©tricas simult√°neamente.

2. **Diferencia m√°s marcada:** Se observa en "Recall Venenoso", donde k-NN alcanza 100% (esquina del pol√≠gono) mientras NB muestra ligera retracci√≥n (93.49%).

3. **M√©tricas casi id√©nticas:** Accuracy y F1-Score muestran diferencias m√≠nimas, confirmando que ambos son excelentes pero k-NN es marginalmente superior.

**Conclusi√≥n visual inmediata:**

El √°rea verde (k-NN) abarcando completamente el √°rea morada (NB) confirma superioridad absoluta en este dataset espec√≠fico. La escala amplificada revela diferencias que ser√≠an invisibles en un radar 0-100% est√°ndar.

<br>

## Comparaci√≥n entre Clases Reales y Predicciones de Ambos Modelos

### Tabla Comparativa de Predicciones
```{r comparacion-real-vs-predicciones}

# Preparaci√≥n de datos (limpieza de etiquetas)
comparacion_predicciones <- data.frame(
  Indice = 1:nrow(test_data),
  Clase_Real = test_data$class,
  Pred_BernoulliNB = pred_nb,
  Pred_KNN = pred_knn_final
) %>%
  mutate(
    BNB_Correcto = ifelse(Clase_Real == Pred_BernoulliNB, "‚úÖ", "‚ùå"),
    KNN_Correcto = ifelse(Clase_Real == Pred_KNN, "‚úÖ", "‚ùå"),
    
    # Simplificamos etiquetas para que quepan mejor
    Error_BNB = case_when(
      Clase_Real == Pred_BernoulliNB ~ "Correcto",
      Clase_Real == "e" & Pred_BernoulliNB == "p" ~ "FP (e‚Üíp)",
      Clase_Real == "p" & Pred_BernoulliNB == "e" ~ "FN (p‚Üíe) ‚ö†Ô∏è",
      TRUE ~ "-"
    ),
    
    Discrepancia = ifelse(Pred_BernoulliNB != Pred_KNN, "‚ö†Ô∏è Difieren", "Coinciden")
  )

# Renderizado de la tabla corregida
# Guardamos el subset para buena configuraci√≥n tabla
tabla_final <- head(comparacion_predicciones, 20)

kable(
  tabla_final,
  col.names = c("Caso", "Real", "BNB", "k-NN", "BNB ‚úì", "k-NN ‚úì", "Detalle Error", "Discrepancia"),
  align = "cccccccc",
  caption = "Comparaci√≥n de Predicciones: Real vs Bernoulli NB vs k-NN"
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = TRUE, # IMPORTANTE: Evita que las celdas se compriman
    position = "center",
    font_size = 13
  ) %>%
  row_spec(0, bold = TRUE, background = "#2c3e50", color = "white") %>%
  # Formateo condicional corregido para la columna "Detalle Error"
  column_spec(7, bold = TRUE, color = case_when(
    tabla_final$Error_BNB == "Correcto" ~ "#27AE60",
    grepl("FN", tabla_final$Error_BNB) ~ "red",
    TRUE ~ "black"
  )) %>%
  # Resaltar la discrepancia
  column_spec(8, color = ifelse(tabla_final$Discrepancia == "Coinciden", "#7F8C8D", "#E67E22"))


cat("\nüìä Resumen de Predicciones:\n")
cat("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n")
cat(sprintf("  Total de observaciones: %d\n", nrow(test_data)))
cat(sprintf("  Bernoulli NB correctas: %d (%.2f%%)\n", 
            sum(comparacion_predicciones$BNB_Correcto == "‚úÖ"),
            mean(comparacion_predicciones$BNB_Correcto == "‚úÖ") * 100))
cat(sprintf("  k-NN correctas: %d (%.2f%%)\n", 
            sum(comparacion_predicciones$KNN_Correcto == "‚úÖ"),
            mean(comparacion_predicciones$KNN_Correcto == "‚úÖ") * 100))
cat(sprintf("  Casos donde difieren: %d\n", 
            sum(comparacion_predicciones$Discrepancia == "‚ö†Ô∏è Difieren")))
```

### Visualizaci√≥n de Concordancia entre Modelos
```{r viz-concordancia-modelos, fig.width=14, fig.height=7}

# Gr√°fico de concordancia
concordancia_df <- comparacion_predicciones %>%
  mutate(
    Categoria = case_when(
      Clase_Real == Pred_BernoulliNB & Clase_Real == Pred_KNN ~ "Ambos Correctos",
      Clase_Real != Pred_BernoulliNB & Clase_Real == Pred_KNN ~ "Solo k-NN Correcto",
      Clase_Real == Pred_BernoulliNB & Clase_Real != Pred_KNN ~ "Solo NBB Correcto",
      TRUE ~ "Ambos Incorrectos"
    ),
    Categoria = factor(Categoria, levels = c("Ambos Correctos", "Solo k-NN Correcto", 
                                              "Solo BNB Correcto", "Ambos Incorrectos"))
  )

ggplot(concordancia_df, aes(x = Categoria, fill = Categoria)) +
  geom_bar(alpha = 0.85, width = 0.7) +
  geom_text(stat = 'count', aes(label = after_stat(count)), 
            vjust = -0.5, size = 6, fontface = "bold") +
  scale_fill_manual(
    values = c(
      "Ambos Correctos" = "#27AE60",
      "Solo k-NN Correcto" = "#3498DB", 
      "Solo BNB Correcto" = "#9B59B6",
      "Ambos Incorrectos" = "#E74C3C"
    )
  ) +
  labs(
    title = "Concordancia entre Modelos: NB Bernoulli vs k-NN",
    subtitle = "Comparaci√≥n de aciertos individuales por observaci√≥n",
    x = "Categor√≠a de Resultado",
    y = "N√∫mero de Observaciones"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 18),
    plot.subtitle = element_text(hjust = 0.5, size = 13),
    axis.text.x = element_text(angle = 15, hjust = 1, size = 12),
    legend.position = "none"
  )
```
<br>

**Conclusiones del An√°lisis de Predicciones**

A partir de la comparaci√≥n de modelos y el an√°lisis de concordancia, se desprenden los siguientes puntos clave:

* **Dominio del modelo k-NN**: El algoritmo k-NN alcanz√≥ una precisi√≥n perfecta (**100%**) en el conjunto de prueba, superando el **94.09%** obtenido por Bernoulli Naive Bayes.
* **Margen de Error en BNB**: Se identificaron **96 casos** donde solo k-NN acert√≥, lo que representa un **5.91%** de discrepancia donde Naive Bayes fall√≥ en capturar la complejidad de los datos.
* **Concordancia**: Ambos modelos coinciden en el **94.09%** de las predicciones ("Ambos Correctos"), lo que valida la consistencia general del preprocesamiento.

**Veredicto:** El modelo **k-NN** es el m√°s robusto para este problema, eliminando por completo los errores de clasificaci√≥n en este set de datos.

<br>

### Resumen estad√≠stico
```{r Resumen estad√≠stico}

# Resumen estad√≠stico
table(concordancia_df$Categoria) %>%
  as.data.frame() %>%
  rename(Categoria = Var1, Frecuencia = Freq) %>%
  mutate(Porcentaje = sprintf("%.2f%%", (Frecuencia/sum(Frecuencia))*100)) %>%
  kable(
    align = "lcc", 
    caption = "üîç An√°lisis de Concordancia"
  ) %>%
  kable_styling(
    bootstrap_options = "striped", 
    full_width = TRUE,
    position = "center"
  )
```

**An√°lisis de Concordancia entre Modelos**

El modelo k-NN alcanz√≥ una precisi√≥n perfecta del 100% en el conjunto de prueba, clasificando correctamente todas las observaciones. En contraste, Bernoulli Naive Bayes obtuvo una precisi√≥n del 94.09%, registrando 96 errores de clasificaci√≥n que corresponden exactamente a los casos donde √∫nicamente k-NN acert√≥.

La concordancia entre ambos modelos alcanza el 94.09%, indicando que comparten predicciones correctas en la mayor√≠a de las observaciones. Sin embargo, el 5.91% de discrepancia corresponde exclusivamente a errores del modelo Naive Bayes, ya que k-NN no cometi√≥ ning√∫n error de clasificaci√≥n. Esta diferencia sugiere que k-NN captura mejor la estructura no lineal presente en las relaciones entre caracter√≠sticas del conjunto de datos de hongos.

Para este problema espec√≠fico, k-NN demuestra ser el clasificador m√°s robusto, eliminando completamente los errores de clasificaci√≥n y superando las limitaciones del supuesto de independencia condicional que caracteriza a Naive Bayes. La ausencia de casos donde ambos modelos fallen simult√°neamente confirma que los 96 errores de BNB son corregibles mediante la metodolog√≠a de vecinos m√°s cercanos.

### An√°lisis de Casos Discrepantes
```{r analisis-casos-discrepantes}

# Filtrar solo casos donde los modelos difieren
casos_discrepantes <- comparacion_predicciones %>%
  filter(Discrepancia == "‚ö†Ô∏è Difieren") %>%
  select(Indice, Clase_Real, Pred_BernoulliNB, Pred_KNN, Error_BNB)

if(nrow(casos_discrepantes) > 0) {
  cat("\n‚ö†Ô∏è CASOS CR√çTICOS: Modelos con Predicciones Diferentes\n\n")
  
  kable(
    head(casos_discrepantes, 15),
    col.names = c("Caso", "Real", "Predicci√≥n BNB", "Predicci√≥n k-NN", "Error BNB"),
    align = "ccccc",
    caption = "Primeros 15 casos donde los modelos discrepan"
  ) %>%
    kable_styling(bootstrap_options = c("striped", "hover")) %>%
    row_spec(0, bold = TRUE, background = "#e74c3c", color = "white")
  
  cat(sprintf("\nüí° Interpretaci√≥n: En %d casos,k-NN acert√≥ donde NB Bernoulli fall√≥.\n", 
              nrow(casos_discrepantes)))
  cat("   Estos casos representan situaciones donde las interacciones entre variables\n")
  cat("   son cr√≠ticas para la clasificaci√≥n correcta.\n")
} else {
  cat("\n‚úÖ No existen casos discrepantes. Ambos modelos producen predicciones id√©nticas.\n")
}
```
<br>
<br>

# Conclusi√≥n Final

## Logros del Estudio

Este proyecto ha demostrado una implementaci√≥n rigurosa y metodol√≥gicamente s√≥lida de Bernoulli Naive Bayes aplicado a clasificaci√≥n binaria de hongos, estableciendo un marco de an√°lisis comparativo que trasciende la simple evaluaci√≥n de m√©tricas de desempe√±o.

**Validaci√≥n exhaustiva del algoritmo en datos discretos**

El modelo Bernoulli Naive Bayes alcanz√≥ un accuracy del 94.09 por ciento sobre el conjunto de prueba, confirmando su capacidad para capturar patrones discriminantes efectivos en variables binarias generadas mediante codificaci√≥n one-hot. El √≠ndice Kappa de 0.88 descarta categ√≥ricamente que esta concordancia se deba al azar, estableciendo que el modelo aprende genuinamente la estructura subyacente del problema. Particularmente revelador resulta que las variables identificadas como m√°s discriminantes por el modelo, espec√≠ficamente aquellas relacionadas con olor ausente, olor f√©tido y caracter√≠sticas de la superficie del tallo, coinciden precisamente con los criterios empleados por taxonom√≠a micol√≥gica experta para clasificaci√≥n de especies. Esta convergencia entre el conocimiento algor√≠tmico extra√≠do mediante an√°lisis de importancia de variables y el conocimiento del dominio establecido por mic√≥logos valida la coherencia cient√≠fica del enfoque.

**An√°lisis diferenciado de riesgo y priorizaci√≥n de errores cr√≠ticos**

El estudio identific√≥ y document√≥ meticulosamente 51 falsos negativos, representando el 6.5 por ciento de los hongos venenosos en el conjunto de prueba. Estos casos, donde el modelo clasifica err√≥neamente espec√≠menes t√≥xicos como comestibles, constituyen el error cr√≠tico que determina la viabilidad operacional del sistema en aplicaciones reales de seguridad alimentaria. Las curvas ROC y Precision-Recall, ambas con √°reas bajo la curva aproximadas de 0.95, revelan el trade-off ajustable entre sensibilidad y especificidad inherente al problema. Este an√°lisis adopta correctamente un enfoque pedag√≥gico donde la detecci√≥n de la clase peligrosa se prioriza sistem√°ticamente sobre la accuracy global, reconociendo que en dominios de alto riesgo las consecuencias de diferentes tipos de errores son asim√©tricas y deben evaluarse bajo criterios diferenciados.

**Comparaci√≥n algor√≠tmica rigurosa y an√°lisis de limitaciones estructurales**

K-Nearest Neighbors con k igual a uno alcanz√≥ clasificaci√≥n perfecta, logrando cien por ciento de accuracy con cero falsos negativos al explotar eficientemente la separabilidad lineal casi perfecta presente en el dataset Mushroom. El contraste sistem√°tico entre ambos modelos revela la limitaci√≥n fundamental de Bernoulli Naive Bayes en este contexto espec√≠fico. El supuesto de independencia condicional entre atributos, aunque computacionalmente conveniente y matem√°ticamente elegante, no puede capturar interacciones cr√≠ticas entre variables como olor, color del sombrero y h√°bitat que conjuntamente determinan toxicidad. La matriz de correlaciones condicionales dentro de cada clase, documentada exhaustivamente mediante an√°lisis ggpairs, muestra valores entre 0.5 y 0.85 en pares de variables clave, violando severamente el supuesto naive. Aunque el test de McNemar resulta no aplicable debido a la diferencia extrema en desempe√±o, el an√°lisis detallado de los 96 casos discordantes proporciona insights m√°s reveladores sobre d√≥nde y por qu√© Naive Bayes falla sistem√°ticamente.

## Fortalezas Metodol√≥gicas del An√°lisis

El estudio implement√≥ verificaci√≥n expl√≠cita del tipo de Naive Bayes mediante inspecci√≥n de la naturaleza binaria estricta de todas las variables predictoras, asegurando que la variante Bernoulli era genuinamente apropiada versus alternativas como Gaussian o Multinomial. La validaci√≥n cruzada de diez folds con an√°lisis de estabilidad estableci√≥ que el desempe√±o observado no constituye un artefacto de una partici√≥n afortunada de datos sino un resultado robusto y reproducible. Crucialmente, el proyecto mantuvo interpretaci√≥n contextual de m√©tricas en lugar de limitarse a reportar n√∫meros aislados, conectando cada resultado cuantitativo con implicaciones pr√°cticas para el problema de clasificaci√≥n de hongos. Finalmente, el an√°lisis incluy√≥ advertencias √©ticas expl√≠citas sobre la naturaleza sint√©tica del dataset, reconociendo que la separabilidad perfecta observada no refleja completamente la variabilidad y ambig√ºedad presentes en espec√≠menes recolectados en campo bajo condiciones naturales.

## Lecciones Fundamentales para Machine Learning

Bernoulli Naive Bayes emerge como un algoritmo r√°pido, interpretable y robusto que constituye una elecci√≥n ideal para establecer baselines iniciales cuando se trabaja con variables categ√≥ricas o binarias. Su simplicidad computacional y la transparencia de su proceso de decisi√≥n mediante probabilidades condicionales lo hacen particularmente valioso en fases exploratorias de proyectos de ciencia de datos. Sin embargo, el estudio demuestra contundentemente que los supuestos algor√≠tmicos importan de manera cr√≠tica. La independencia condicional asumida por Naive Bayes penaliza severamente el desempe√±o en problemas donde interacciones fuertes entre variables contienen informaci√≥n discriminante esencial que no puede recuperarse evaluando atributos aisladamente.

K-Nearest Neighbors logra accuracy perfecta en este problema espec√≠fico, pero esta superioridad viene acompa√±ada de costos computacionales significativos. El algoritmo requiere orden de n multiplicado por p comparaciones por cada predicci√≥n individual versus orden de p evaluaciones para Bernoulli Naive Bayes. En datasets masivos con m√°s de cien mil observaciones, esta diferencia de complejidad computacional hace que KNN se vuelva prohibitivo para implementaciones en tiempo real o sistemas con restricciones de latencia. El estudio ilustra que la selecci√≥n de algoritmos debe guiarse no √∫nicamente por accuracy en conjuntos de validaci√≥n sino por consideraci√≥n integral de trade-offs entre precisi√≥n, interpretabilidad, eficiencia computacional y alineaci√≥n entre supuestos del modelo y estructura real de los datos.

Finalmente, el an√°lisis enfatiza que las m√©tricas deben contextualizarse seg√∫n el dominio de aplicaci√≥n. En problemas de seguridad como clasificaci√≥n de toxicidad, el recall de la clase peligrosa debe priorizarse sistem√°ticamente sobre accuracy global, reflejando que las consecuencias de falsos negativos y falsos positivos son fundamentalmente asim√©tricas y deben ponderarse diferencialmente en la funci√≥n de p√©rdida.

## Veredicto para Este Problema Espec√≠fico

K-Nearest Neighbors constituye el ganador indiscutible para el dataset Mushroom espec√≠fico al eliminar completamente los 51 falsos negativos cr√≠ticos presentes en Bernoulli Naive Bayes, logrando separaci√≥n perfecta entre clases. No obstante, el valor cient√≠fico profundo de este estudio no reside meramente en identificar cu√°l modelo alcanza mayor accuracy, sino en elucidar rigurosamente cu√°ndo y por qu√© fallan los supuestos de Naive Bayes. El proyecto demuestra que la violaci√≥n del supuesto de independencia condicional en presencia de interacciones multivariadas fuertes constituye la causa ra√≠z de los errores observados, proporcionando comprensi√≥n mecan√≠stica en lugar de comparaciones superficiales de n√∫meros.

Esta investigaci√≥n establece principios generalizables aplicables m√°s all√° del dominio espec√≠fico de micolog√≠a. En cualquier problema de clasificaci√≥n donde estructura de dependencias entre variables sea compleja y consecuencias de errores sean asim√©tricas, la selecci√≥n informada de algoritmos debe fundamentarse en an√°lisis riguroso de supuestos, validaci√≥n exhaustiva de condiciones de aplicabilidad y evaluaci√≥n multidimensional que considere simult√°neamente precisi√≥n predictiva, interpretabilidad, eficiencia computacional y robustez ante variabilidad natural de datos reales. El estudio proporciona un template metodol√≥gico para an√°lisis comparativos que balancean rigor t√©cnico con claridad pedag√≥gica, demostrando que machine learning efectivo requiere no solo implementaci√≥n correcta de algoritmos sino comprensi√≥n profunda de sus fundamentos te√≥ricos y limitaciones pr√°cticas.


# Referencias

- Deisenroth, M. P., Faisal, A. A., & Ong, C. S. (2020). Mathematics for machine learning. Cambridge University Press.

- Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning: Data mining, inference, and prediction (2.¬™ ed.). Springer.

- Gujarati, D. N. (2004). Econometr√≠a (5.¬™ ed.). McGraw-Hill Interamericana.
