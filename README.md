# üìä Clasificaci√≥n de Hongos: Rigurosidad Estad√≠stica y Desaf√≠o de Supuestos

[![Reporte en HTML](https://img.shields.io/badge/VER_REPORTE_INTERACTIVO-HTML-blue?style=for-the-badge&logo=html5)](https://alej2andro.github.io/Mushroom-Classification-Bernoulli-Naive-Bayes-vs-K-Nearest-Neighbors-Algorithms/)
[![RPubs](https://img.shields.io/badge/Portafolio-RPubs-orange?style=for-the-badge&logo=r)](https://rpubs.com/Alej5ndro)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Perfil-0077B5?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/alejandrofigueroarojas)
[![Email](https://img.shields.io/badge/Email-Contacto-D14836?style=for-the-badge&logo=gmail)](mailto:alejandro.figueroa,rojas@gmail.com)

---

## üîç Filosof√≠a y Enfoque
Mi aproximaci√≥n a la **Ciencia de Datos** no se limita a la ejecuci√≥n de algoritmos "caja negra". Mi trabajo se basa en la **rigurosidad matem√°tica** y el estudio profundo de la naturaleza de los datos. Creo firmemente que la eficacia de un modelo reside en el respeto a sus supuestos y en la disciplina del an√°lisis exploratorio.

> *"Un modelo no es solo una predicci√≥n, es una hip√≥tesis sobre la estructura del mundo."*

## üçÑ Resumen del Proyecto: Bernoulli NB vs. KNN
Este proyecto analiza la separabilidad de clases (Comestible vs. Venenoso) en un dataset de hongos, contrastando dos paradigmas algor√≠tmicos distintos para evaluar c√≥mo la estructura de los datos afecta el rendimiento del modelo.

### üî¨ Puntos Clave del An√°lisis:
* **Diagn√≥stico de Supuestos**: Evaluaci√≥n cr√≠tica de la **independencia condicional** requerida por Naive Bayes. A trav√©s de una matriz de correlaciones avanzada, identifico violaciones severas (correlaciones de hasta 0.848) que explican las limitaciones predictivas del modelo.
* **Matriz de Separabilidad**: Implementaci√≥n de visualizaciones complejas en `ggplot2` para analizar la distribuci√≥n bimodal y la estructura discreta de las variables m√°s discriminantes.
* **Contraste de Paradigmas**:
    * **Bernoulli Naive Bayes**: Evaluado bajo la √≥ptica de la probabilidad condicional y la distribuci√≥n de Bernoulli.
    * **K-Nearest Neighbors (KNN)**: Utilizado para capturar la geometr√≠a local y las interacciones que Naive Bayes ignora por dise√±o.
* **Optimizaci√≥n y Validaci√≥n**: Uso de validaci√≥n cruzada (10-fold CV) para asegurar la robustez de las m√©tricas de desempe√±o y evitar el sobreajuste.

## üõ†Ô∏è Stack T√©cnico
* **Lenguaje**: R (Tidyverse, Caret, GGally, ggplot2).
* **Disciplina Matem√°tica**: Estad√≠stica Bayesiana, Probabilidad Condicional, Geometr√≠a de Datos.
* **Documentaci√≥n**: RMarkdown para la creaci√≥n de reportes cient√≠ficos reproducibles y din√°micos.

---

## üìà Conclusi√≥n T√©cnica
El modelo Naive Bayes alcanz√≥ un **94.09% de accuracy**. Sin embargo, el an√°lisis profundo revela que este √©xito es parcial: la violaci√≥n del supuesto de independencia genera **51 falsos negativos**. Este proyecto documenta emp√≠ricamente por qu√© la estructura de dependencias en los atributos morfol√≥gicos requiere modelos que capturen interacciones complejas, como KNN, el cual logra corregir estas desviaciones.

---

**Alejandro Figueroa Rojas** *Comprometido con la precisi√≥n anal√≠tica y la disciplina en la ciencia de datos.*

---

### Acceso al Proyecto
1. **Explorar el c√≥digo**: El archivo `Bernoullinb.Rmd` contiene el flujo de trabajo completo.
2. **Visualizar Reporte**: [Haz clic aqu√≠ para ver el an√°lisis renderizado en HTML](https://alej2andro.github.io/Mushroom-Classification-Bernoulli-Naive-Bayes-vs-K-Nearest-Neighbors-Algorithms/).
